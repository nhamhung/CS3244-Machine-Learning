{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EyfG4JyRXCEz",
        "suSQxllQgs48",
        "QBT62747CQmC",
        "SGnKHCmtE_mq",
        "pQd_RO8OsYrs",
        "U9wGPylU8Kv7",
        "VzVXfQ3bji-P"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMO9cEwy1qNBZtdMNVAkujc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhamhung/CS3244-Machine-Learning/blob/main/TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL6aDWVv71Me",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "470f6b89-1d54-49e8-a225-acbcc1b7c98c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAdMLr4F8gpL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "9ececdb6-5f1a-4bc1-8f79-2e6a0ce2590c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json \n",
        "import os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "\n",
        "df_train = pd.read_csv('/content/drive/My Drive/CS3244 Project/train_lemmatized.csv')\n",
        "df_test = pd.read_csv('/content/drive/My Drive/CS3244 Project/test_lemmatized.csv')\n",
        "df_test_labels = pd.read_csv('/content/drive/My Drive/CS3244 Project/test_labels.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-acd754afa58e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/CS3244 Project/train_lemmatized.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/CS3244 Project/test_lemmatized.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf_test_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/CS3244 Project/test_labels.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/CS3244 Project/test_labels.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyfG4JyRXCEz"
      },
      "source": [
        "# Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70Gc18jUYNon"
      },
      "source": [
        "def lower(s):\n",
        "  return s.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0N_rQ1WYkk9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "8c8362c0-3c7a-4d7c-b894-534327b1e8f8"
      },
      "source": [
        "!pip install contractions\n",
        "import contractions\n",
        "sample_abbr = {\n",
        "    \"$\" : \" dollar \",\n",
        "    \"€\" : \" euro \",\n",
        "    \"4ao\" : \"for adults only\",\n",
        "    \"a.m\" : \"before midday\",\n",
        "    \"a3\" : \"anytime anywhere anyplace\",\n",
        "    \"aamof\" : \"as a matter of fact\",\n",
        "    \"acct\" : \"account\",\n",
        "    \"adih\" : \"another day in hell\",\n",
        "    \"afaic\" : \"as far as i am concerned\",\n",
        "    \"afaict\" : \"as far as i can tell\",\n",
        "    \"afaik\" : \"as far as i know\",\n",
        "    \"afair\" : \"as far as i remember\",\n",
        "    \"afk\" : \"away from keyboard\",\n",
        "    \"app\" : \"application\",\n",
        "    \"approx\" : \"approximately\",\n",
        "    \"apps\" : \"applications\",\n",
        "    \"asap\" : \"as soon as possible\",\n",
        "    \"asl\" : \"age, sex, location\",\n",
        "    \"atk\" : \"at the keyboard\",\n",
        "    \"ave.\" : \"avenue\",\n",
        "    \"aymm\" : \"are you my mother\",\n",
        "    \"ayor\" : \"at your own risk\", \n",
        "    \"b&b\" : \"bed and breakfast\",\n",
        "    \"b+b\" : \"bed and breakfast\",\n",
        "    \"b.c\" : \"before christ\",\n",
        "    \"b2b\" : \"business to business\",\n",
        "    \"b2c\" : \"business to customer\",\n",
        "    \"b4\" : \"before\",\n",
        "    \"b4n\" : \"bye for now\",\n",
        "    \"b@u\" : \"back at you\",\n",
        "    \"bae\" : \"before anyone else\",\n",
        "    \"bak\" : \"back at keyboard\",\n",
        "    \"bbbg\" : \"bye bye be good\",\n",
        "    \"bbc\" : \"british broadcasting corporation\",\n",
        "    \"bbias\" : \"be back in a second\",\n",
        "    \"bbl\" : \"be back later\",\n",
        "    \"bbs\" : \"be back soon\",\n",
        "    \"be4\" : \"before\",\n",
        "    \"bfn\" : \"bye for now\",\n",
        "    \"blvd\" : \"boulevard\",\n",
        "    \"bout\" : \"about\",\n",
        "    \"brb\" : \"be right back\",\n",
        "    \"bros\" : \"brothers\",\n",
        "    \"brt\" : \"be right there\",\n",
        "    \"bsaaw\" : \"big smile and a wink\",\n",
        "    \"btw\" : \"by the way\",\n",
        "    \"bwl\" : \"bursting with laughter\",\n",
        "    \"c/o\" : \"care of\",\n",
        "    \"cet\" : \"central european time\",\n",
        "    \"cf\" : \"compare\",\n",
        "    \"cia\" : \"central intelligence agency\",\n",
        "    \"csl\" : \"can not stop laughing\",\n",
        "    \"cu\" : \"see you\",\n",
        "    \"cul8r\" : \"see you later\",\n",
        "    \"cv\" : \"curriculum vitae\",\n",
        "    \"cwot\" : \"complete waste of time\",\n",
        "    \"cya\" : \"see you\",\n",
        "    \"cyt\" : \"see you tomorrow\",\n",
        "    \"dae\" : \"does anyone else\",\n",
        "    \"dbmib\" : \"do not bother me i am busy\",\n",
        "    \"diy\" : \"do it yourself\",\n",
        "    \"dm\" : \"direct message\",\n",
        "    \"dwh\" : \"during work hours\",\n",
        "    \"e123\" : \"easy as one two three\",\n",
        "    \"eet\" : \"eastern european time\",\n",
        "    \"eg\" : \"example\",\n",
        "    \"embm\" : \"early morning business meeting\",\n",
        "    \"encl\" : \"enclosed\",\n",
        "    \"encl.\" : \"enclosed\",\n",
        "    \"etc\" : \"and so on\",\n",
        "    \"faq\" : \"frequently asked questions\",\n",
        "    \"fawc\" : \"for anyone who cares\",\n",
        "    \"fb\" : \"facebook\",\n",
        "    \"fc\" : \"fingers crossed\",\n",
        "    \"fig\" : \"figure\",\n",
        "    \"fimh\" : \"forever in my heart\", \n",
        "    \"ft.\" : \"feet\",\n",
        "    \"ft\" : \"featuring\",\n",
        "    \"ftl\" : \"for the loss\",\n",
        "    \"ftw\" : \"for the win\",\n",
        "    \"fwiw\" : \"for what it is worth\",\n",
        "    \"fyi\" : \"for your information\",\n",
        "    \"g9\" : \"genius\",\n",
        "    \"gahoy\" : \"get a hold of yourself\",\n",
        "    \"gal\" : \"get a life\",\n",
        "    \"gcse\" : \"general certificate of secondary education\",\n",
        "    \"gfn\" : \"gone for now\",\n",
        "    \"gg\" : \"good game\",\n",
        "    \"gl\" : \"good luck\",\n",
        "    \"glhf\" : \"good luck have fun\",\n",
        "    \"gmt\" : \"greenwich mean time\",\n",
        "    \"gmta\" : \"great minds think alike\",\n",
        "    \"gn\" : \"good night\",\n",
        "    \"g.o.a.t\" : \"greatest of all time\",\n",
        "    \"goat\" : \"greatest of all time\",\n",
        "    \"goi\" : \"get over it\",\n",
        "    \"gps\" : \"global positioning system\",\n",
        "    \"gr8\" : \"great\",\n",
        "    \"gratz\" : \"congratulations\",\n",
        "    \"gyal\" : \"girl\",\n",
        "    \"h&c\" : \"hot and cold\",\n",
        "    \"hp\" : \"horsepower\",\n",
        "    \"hr\" : \"hour\",\n",
        "    \"hrh\" : \"his royal highness\",\n",
        "    \"ht\" : \"height\",\n",
        "    \"ibrb\" : \"i will be right back\",\n",
        "    \"ic\" : \"i see\",\n",
        "    \"icq\" : \"i seek you\",\n",
        "    \"icymi\" : \"in case you missed it\",\n",
        "    \"idc\" : \"i do not care\",\n",
        "    \"idgadf\" : \"i do not give a damn fuck\",\n",
        "    \"idgaf\" : \"i do not give a fuck\",\n",
        "    \"idk\" : \"i do not know\",\n",
        "    \"ie\" : \"that is\",\n",
        "    \"i.e\" : \"that is\",\n",
        "    \"ifyp\" : \"i feel your pain\",\n",
        "    \"IG\" : \"instagram\",\n",
        "    \"iirc\" : \"if i remember correctly\",\n",
        "    \"ilu\" : \"i love you\",\n",
        "    \"ily\" : \"i love you\",\n",
        "    \"imho\" : \"in my humble opinion\",\n",
        "    \"imo\" : \"in my opinion\",\n",
        "    \"imu\" : \"i miss you\",\n",
        "    \"iow\" : \"in other words\",\n",
        "    \"irl\" : \"in real life\",\n",
        "    \"j4f\" : \"just for fun\",\n",
        "    \"jic\" : \"just in case\",\n",
        "    \"jk\" : \"just kidding\",\n",
        "    \"jsyk\" : \"just so you know\",\n",
        "    \"l8r\" : \"later\",\n",
        "    \"lb\" : \"pound\",\n",
        "    \"lbs\" : \"pounds\",\n",
        "    \"ldr\" : \"long distance relationship\",\n",
        "    \"lmao\" : \"laugh my ass off\",\n",
        "    \"lmfao\" : \"laugh my fucking ass off\",\n",
        "    \"lol\" : \"laughing out loud\",\n",
        "    \"ltd\" : \"limited\",\n",
        "    \"ltns\" : \"long time no see\",\n",
        "    \"m8\" : \"mate\",\n",
        "    \"mf\" : \"motherfucker\",\n",
        "    \"mfs\" : \"motherfuckers\",\n",
        "    \"mfw\" : \"my face when\",\n",
        "    \"mofo\" : \"motherfucker\",\n",
        "    \"mph\" : \"miles per hour\",\n",
        "    \"mr\" : \"mister\",\n",
        "    \"mrw\" : \"my reaction when\",\n",
        "    \"ms\" : \"miss\",\n",
        "    \"mte\" : \"my thoughts exactly\",\n",
        "    \"nagi\" : \"not a good idea\",\n",
        "    \"nbc\" : \"national broadcasting company\",\n",
        "    \"nbd\" : \"not big deal\",\n",
        "    \"nfs\" : \"not for sale\",\n",
        "    \"ngl\" : \"not going to lie\",\n",
        "    \"nhs\" : \"national health service\",\n",
        "    \"nrn\" : \"no reply necessary\",\n",
        "    \"nsfl\" : \"not safe for life\",\n",
        "    \"nsfw\" : \"not safe for work\",\n",
        "    \"nth\" : \"nice to have\",\n",
        "    \"nvr\" : \"never\",\n",
        "    \"nyc\" : \"new york city\",\n",
        "    \"oc\" : \"original content\",\n",
        "    \"og\" : \"original\",\n",
        "    \"ohp\" : \"overhead projector\",\n",
        "    \"oic\" : \"oh i see\",\n",
        "    \"omdb\" : \"over my dead body\",\n",
        "    \"omg\" : \"oh my god\",\n",
        "    \"omw\" : \"on my way\",\n",
        "    \"p.a\" : \"per annum\",\n",
        "    \"p.m\" : \"after midday\",\n",
        "    \"pm\" : \"prime minister\",\n",
        "    \"poc\" : \"people of color\",\n",
        "    \"pov\" : \"point of view\",\n",
        "    \"pp\" : \"pages\",\n",
        "    \"ppl\" : \"people\",\n",
        "    \"prw\" : \"parents are watching\",\n",
        "    \"ps\" : \"postscript\",\n",
        "    \"pt\" : \"point\",\n",
        "    \"ptb\" : \"please text back\",\n",
        "    \"pto\" : \"please turn over\",\n",
        "    \"qpsa\" : \"what happens\", #\"que pasa\",\n",
        "    \"ratchet\" : \"rude\",\n",
        "    \"rbtl\" : \"read between the lines\",\n",
        "    \"rlrt\" : \"real life retweet\", \n",
        "    \"rofl\" : \"rolling on the floor laughing\",\n",
        "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
        "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
        "    \"rt\" : \"retweet\",\n",
        "    \"ruok\" : \"are you ok\",\n",
        "    \"sfw\" : \"safe for work\",\n",
        "    \"sk8\" : \"skate\",\n",
        "    \"smh\" : \"shake my head\",\n",
        "    \"sq\" : \"square\",\n",
        "    \"srsly\" : \"seriously\", \n",
        "    \"ssdd\" : \"same stuff different day\",\n",
        "    \"tbh\" : \"to be honest\",\n",
        "    \"tbs\" : \"tablespooful\",\n",
        "    \"tbsp\" : \"tablespooful\",\n",
        "    \"tfw\" : \"that feeling when\",\n",
        "    \"thks\" : \"thank you\",\n",
        "    \"tho\" : \"though\",\n",
        "    \"thx\" : \"thank you\",\n",
        "    \"tia\" : \"thanks in advance\",\n",
        "    \"til\" : \"today i learned\",\n",
        "    \"tl;dr\" : \"too long i did not read\",\n",
        "    \"tldr\" : \"too long i did not read\",\n",
        "    \"tmb\" : \"tweet me back\",\n",
        "    \"tntl\" : \"trying not to laugh\",\n",
        "    \"ttyl\" : \"talk to you later\",\n",
        "    \"u\" : \"you\",\n",
        "    \"u2\" : \"you too\",\n",
        "    \"u4e\" : \"yours for ever\",\n",
        "    \"utc\" : \"coordinated universal time\",\n",
        "    \"w/\" : \"with\",\n",
        "    \"w/o\" : \"without\",\n",
        "    \"w8\" : \"wait\",\n",
        "    \"wassup\" : \"what is up\",\n",
        "    \"wb\" : \"welcome back\",\n",
        "    \"wtf\" : \"what the fuck\",\n",
        "    \"wtg\" : \"way to go\",\n",
        "    \"wtpa\" : \"where the party at\",\n",
        "    \"wuf\" : \"where are you from\",\n",
        "    \"wuzup\" : \"what is up\",\n",
        "    \"wywh\" : \"wish you were here\",\n",
        "    \"yd\" : \"yard\",\n",
        "    \"ygtr\" : \"you got that right\",\n",
        "    \"ynk\" : \"you never know\",\n",
        "    \"zzz\" : \"sleeping bored and tired\"\n",
        "}\n",
        "for key in sample_abbr.keys():\n",
        "  contractions.add(key, sample_abbr[key])\n",
        "\n",
        "def contraction(s):\n",
        "  return contractions.fix(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/00/92/a05b76a692ac08d470ae5c23873cf1c9a041532f1ee065e74b374f218306/contractions-0.0.25-py2.py3-none-any.whl\n",
            "Collecting textsearch\n",
            "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
            "Collecting pyahocorasick\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 4.6MB/s \n",
            "\u001b[?25hCollecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 8.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-80fdce8ef534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install contractions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcontractions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m sample_abbr = {\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"$\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\" dollar \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"€\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\" euro \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'contractions'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOWkX_5IZfi1"
      },
      "source": [
        "APOSTROPHES = { \n",
        "\"ain't\": \"is not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he'll've\": \"he will have\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"I'd\": \"I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I will\",\n",
        "\"I'll've\": \"I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it'll've\": \"it will have\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she had / she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she'll've\": \"she will have\",\n",
        "\"she's\": \"sshe is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so is\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they'll've\": \"they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what shall\"\n",
        "}\n",
        "\n",
        "def remove_apostrophe(s):\n",
        "    words = s.split()\n",
        "    reformed = [ APOSTROPHES[word] if word in APOSTROPHES else word for word in words ]\n",
        "    reformed = \" \".join(reformed)\n",
        "    return reformed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJF-WTs0cWbE"
      },
      "source": [
        "import re\n",
        "def remove_URL(s):\n",
        "    return re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfbSf787Uf4H"
      },
      "source": [
        "def remove_html(s):\n",
        "    html = re.compile(r\"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\")\n",
        "    return re.sub(html, \"\", s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb4rNEURYzyt"
      },
      "source": [
        "def remove_non_ascii(s):\n",
        "    return re.sub(r\"[^\\x00-\\x7f]\", r\"\", s) # not in range range of char code 0 to 127"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcoNwhIDfpyR"
      },
      "source": [
        "def remove_emoji(s):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\U0001f926-\\U0001f937\"\n",
        "                               u\"\\U00010000-\\U0010ffff\"\n",
        "                               u\"\\u2640-\\u2642\"\n",
        "                               u\"\\u2600-\\u2B55\"\n",
        "                               u\"\\u200d\"\n",
        "                               u\"\\u23cf\"\n",
        "                               u\"\\u23e9\"\n",
        "                               u\"\\u231a\"\n",
        "                               u\"\\ufe0f\"  # dingbats\n",
        "                               u\"\\u3030\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikbi0hF1ftvn"
      },
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(s):\n",
        "    return s.translate(str.maketrans('', '', string.punctuation))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqpQ_b7FEa8H"
      },
      "source": [
        "def remove_number(s):\n",
        "  result = ''.join([i for i in s if not i.isdigit()])\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJKVWGdvTf8K"
      },
      "source": [
        "preprocess('are u gay?68.33.41.181 http://abc google.com')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xC85hSPUtLj"
      },
      "source": [
        "preprocess('Same for File:SeanKilpatrick2014.jpg and File:ConnorBarwinCincy.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syqInpUJXEys"
      },
      "source": [
        "def preprocess(comment):\n",
        "  comment = lower(comment)\n",
        "  comment = contraction(comment)\n",
        "  comment = remove_apostrophe(comment)\n",
        "  comment = remove_number(comment)\n",
        "  comment = remove_URL(comment)\n",
        "  comment = remove_html(comment)\n",
        "  comment = remove_non_ascii(comment)\n",
        "  comment = remove_emoji(comment)\n",
        "  comment = remove_punctuation(comment)\n",
        "  return lower(comment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3RY0cRXf0sY"
      },
      "source": [
        "df_train['clean_text'] = df_train['comment_text'].apply(lambda x: preprocess(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVs2i9kYbHm2"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suSQxllQgs48"
      },
      "source": [
        "# Vectorize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW1zAGbPgurZ"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "df_train['tokenized'] = df_train['clean_text'].apply(word_tokenize)\n",
        "df_train.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbILhWXKiSA7"
      },
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "df_train['stopwords_removed'] = df_train['tokenized'].apply(lambda x: [word for word in x if word not in stop])\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxAeqMydjZae"
      },
      "source": [
        "df_train['stopwords_removed'][2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRNsRNaTjCJ4"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('brown')\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import brown\n",
        "\n",
        "wordnet_map = {\"N\":wordnet.NOUN, \n",
        "               \"V\":wordnet.VERB, \n",
        "               \"J\":wordnet.ADJ, \n",
        "               \"R\":wordnet.ADV\n",
        "              }\n",
        "    \n",
        "train_sents = brown.tagged_sents(categories='news')\n",
        "t0 = nltk.DefaultTagger('NN')\n",
        "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
        "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
        "\n",
        "def pos_tag_wordnet(text, pos_tag_type=\"pos_tag\"):\n",
        "    \"\"\"\n",
        "        Create pos_tag with wordnet format\n",
        "    \"\"\"\n",
        "    pos_tagged_text = t2.tag(text)\n",
        "    \n",
        "    # map the pos tagging output with wordnet output \n",
        "    pos_tagged_text = [(word, wordnet_map.get(pos_tag[0])) if pos_tag[0] in wordnet_map.keys() else (word, wordnet.NOUN) for (word, pos_tag) in pos_tagged_text ] # if tag is in wordnet_map then map also default noun\n",
        "    return pos_tagged_text\n",
        "\n",
        "df_train['combined_postag_wnet'] = df_train['stopwords_removed'].apply(lambda x: pos_tag_wordnet(x))\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1KW0ixjnepv"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def lemmatize_word(text):\n",
        "    \"\"\"\n",
        "        Lemmatize the tokenized words\n",
        "    \"\"\"\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemma = [lemmatizer.lemmatize(word, tag) for word, tag in text]\n",
        "    return lemma\n",
        "\n",
        "df_train['lemmatize_word_w_pos'] = df_train['combined_postag_wnet'].apply(lambda x: lemmatize_word(x))\n",
        "df_train['lemmatize_word_w_pos'] = df_train['lemmatize_word_w_pos'].apply(lambda x: [word for word in x if word not in stop]) # double check to remove stop words\n",
        "df_train['lemmatize_text'] = [' '.join(map(str, l)) for l in df_train['lemmatize_word_w_pos']] # join back to text\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCPZ0HbVwYUL"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5XbrJMGOlF8"
      },
      "source": [
        "df_train.to_csv(\"/content/drive/My Drive/CS3244 Project/train_lemmatized.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwaRkRNQOm6T"
      },
      "source": [
        "df_test.to_csv(\"/content/drive/My Drive/CS3244 Project/test_lemmatized.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ky_Ee7Qn_rj"
      },
      "source": [
        "df_test['clean_text'] = df_test['comment_text'].apply(lambda x:preprocess(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8E_qGr7MR2j"
      },
      "source": [
        "df_test['tokenized'] = df_test['clean_text'].apply(word_tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdZEket_NOA0"
      },
      "source": [
        "stop = set(stopwords.words('english'))\n",
        "df_test['stopwords_removed'] = df_test['tokenized'].apply(lambda x: [word for word in x if word not in stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGvLDiKuODdX"
      },
      "source": [
        "df_test['combined_postag_wnet'] = df_test['stopwords_removed'].apply(lambda x: pos_tag_wordnet(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn3yVuxDOiWK"
      },
      "source": [
        "df_test['lemmatize_word_w_pos'] = df_test['combined_postag_wnet'].apply(lambda x: lemmatize_word(x))\n",
        "df_test['lemmatize_word_w_pos'] = df_test['lemmatize_word_w_pos'].apply(lambda x: [word for word in x if word not in stop]) # double check to remove stop words\n",
        "df_test['lemmatize_text'] = [' '.join(map(str, l)) for l in df_test['lemmatize_word_w_pos']] # join back to text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsUf_6m9FKiM"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NdYX5WlDfZq"
      },
      "source": [
        "# Import packages for pre-processing\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# Import tools to split data and evaluate model performance\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve, fbeta_score, confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "# Import ML algos\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkruQNucZGSV"
      },
      "source": [
        "df_train = df_train.fillna(\"\")\n",
        "df_test = df_test.fillna(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAW5xHqaCZBI"
      },
      "source": [
        "data_tox = df_train.loc[:, ['id', 'lemmatize_text', 'toxic']]\n",
        "data_sev = df_train.loc[:, ['id', 'lemmatize_text', 'severe_toxic']]\n",
        "data_obs = df_train.loc[:, ['id', 'lemmatize_text', 'obscene']]\n",
        "data_thr = df_train.loc[:, ['id', 'lemmatize_text', 'threat']]\n",
        "data_ins = df_train.loc[:, ['id', 'lemmatize_text', 'insult']]\n",
        "data_ide = df_train.loc[:, ['id', 'lemmatize_text', 'identity_hate']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8fxomUBGHOb"
      },
      "source": [
        "'''\n",
        "df_done: data_tox_done, data_sev_done, ...\n",
        "label: toxic, severe_toxic, ...\n",
        "vectorizer values: CountVectorizer, TfidfVectorizer\n",
        "gram_range values: (1,1) for unigram, (2,2) for bigram\n",
        "'''\n",
        "\n",
        "def cv_tf_train_test(df_type,label,vectorizer,ngram):\n",
        "\n",
        "    ''' Train/Test split'''\n",
        "    # Split the data into X and y data sets\n",
        "    X = df_type.lemmatize_text\n",
        "    y = df_type[label]\n",
        "\n",
        "    # Split our data into training and test data \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    ''' Count Vectorizer/TF-IDF '''\n",
        "\n",
        "    # Create a Vectorizer object and remove stopwords from the table\n",
        "    cv1 = vectorizer(ngram_range=(ngram), max_features=5000, strip_accents='unicode', analyzer='word', norm='l2')\n",
        "    \n",
        "    X_train_cv1 = cv1.fit_transform(X_train) # Learn the vocabulary dictionary and return term-document matrix\n",
        "    X_test_cv1  = cv1.transform(X_test)      # Learn a vocabulary dictionary of all tokens in the raw documents.\n",
        "    \n",
        "    # Output a Dataframe of the CountVectorizer with unique words as the labels\n",
        "    # test = pd.DataFrame(X_train_cv1.toarray(), columns=cv1.get_feature_names())\n",
        "        \n",
        "    ''' Initialize all model objects and fit the models on the training data '''\n",
        "    lr = LogisticRegression(max_iter=300)\n",
        "    lr.fit(X_train_cv1, y_train)\n",
        "    print('lr done')\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=5)\n",
        "    knn.fit(X_train_cv1, y_train)\n",
        "    print('knn done')\n",
        "\n",
        "    bnb = BernoulliNB()\n",
        "    bnb.fit(X_train_cv1, y_train)\n",
        "    print('bnb done')\n",
        "    \n",
        "    mnb = MultinomialNB()\n",
        "    mnb.fit(X_train_cv1, y_train)\n",
        "    print('mnb done')\n",
        "    \n",
        "    # svm_model = LinearSVC()\n",
        "    # svm_model.fit(X_train_cv1, y_train)\n",
        "    # print('svm done')\n",
        "\n",
        "    randomforest = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "    randomforest.fit(X_train_cv1, y_train)\n",
        "    print('rdf done')\n",
        "\n",
        "    print(len(y_test))\n",
        "    print(roc_auc_score(y_test, lr.predict_proba(X_test_cv1)[:,1]))    \n",
        "    # Create a list of F1 score of all models \n",
        "    f1_score_data = {'Roc Auc Score':[roc_auc_score(y_test, lr.predict_proba(X_test_cv1)[:,1]), roc_auc_score(y_test, knn.predict_proba(X_test_cv1)[:,1]),\n",
        "                                      roc_auc_score(y_test, bnb.predict_proba(X_test_cv1)[:,1]), roc_auc_score(y_test, mnb.predict_proba(X_test_cv1)[:,1]),\n",
        "                                      roc_auc_score(y_test, svm_model.predict_proba(X_test_cv1)[:,1]), roc_auc_score(y_test, randomforest.predict_proba(X_test_cv1)[:,1])]} \n",
        "                          \n",
        "    # Create DataFrame with the model names as column labels\n",
        "    df_f1 = pd.DataFrame(f1_score_data, index=['Log Regression','KNN', 'BernoulliNB', 'MultinomialNB', '', 'RandomForest'])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT_coXE3QI4P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "f863a6d9-347e-4130-d2b2-2976ffdebef1"
      },
      "source": [
        "'''\n",
        "def cv_tf_train_test(df_done,label,vectorizer,ngram)\n",
        "vectorizer values: CountVectorizer, TfidfVectorizer\n",
        "ngram_range values: (1,1) for unigram, (2,2) for bigram\n",
        "'''\n",
        "\n",
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "df_ide_cv = cv_tf_train_test(data_ide, 'identity_hate', TfidfVectorizer, (1,2))\n",
        "df_ide_cv.rename(columns={'F1 Score': 'F1 Score(identity_hate)', 'Roc Auc Score': 'Roc Auc Score(identity_hate)'}, inplace=True)\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "total = 'Time taken: {} seconds'.format(t1-t0)\n",
        "print(total)\n",
        "\n",
        "df_ide_cv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr done\n",
            "knn done\n",
            "bnb done\n",
            "mnb done\n",
            "svm done\n",
            "rdf done\n",
            "Time taken: 289.2395284175873 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1 Score(identity_hate)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Log Regression</th>\n",
              "      <td>0.287648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.204668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BernoulliNB</th>\n",
              "      <td>0.117614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MultinomialNB</th>\n",
              "      <td>0.165441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.353303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>0.209765</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                F1 Score(identity_hate)\n",
              "Log Regression                 0.287648\n",
              "KNN                            0.204668\n",
              "BernoulliNB                    0.117614\n",
              "MultinomialNB                  0.165441\n",
              "SVM                            0.353303\n",
              "Random Forest                  0.209765"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHsQJa8EQgbk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "2b9971e1-301f-4d4a-b141-acd165d83631"
      },
      "source": [
        "f1_all = pd.concat([df_tox_cv, df_sev_cv, df_obs_cv, df_ins_cv, df_thr_cv, df_ide_cv], axis=1)\n",
        "f1_all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1 Score(toxic)</th>\n",
              "      <th>F1 Score(severe_toxic)</th>\n",
              "      <th>F1 Score(obscene)</th>\n",
              "      <th>F1 Score(insult)</th>\n",
              "      <th>F1 Score(threat)</th>\n",
              "      <th>F1 Score(identity_hate)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Log Regression</th>\n",
              "      <td>0.723269</td>\n",
              "      <td>0.344828</td>\n",
              "      <td>0.734251</td>\n",
              "      <td>0.639721</td>\n",
              "      <td>0.176796</td>\n",
              "      <td>0.287648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.445968</td>\n",
              "      <td>0.243386</td>\n",
              "      <td>0.486952</td>\n",
              "      <td>0.428456</td>\n",
              "      <td>0.176166</td>\n",
              "      <td>0.204668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BernoulliNB</th>\n",
              "      <td>0.341392</td>\n",
              "      <td>0.111934</td>\n",
              "      <td>0.245026</td>\n",
              "      <td>0.229751</td>\n",
              "      <td>0.177340</td>\n",
              "      <td>0.117614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MultinomialNB</th>\n",
              "      <td>0.653518</td>\n",
              "      <td>0.242236</td>\n",
              "      <td>0.665026</td>\n",
              "      <td>0.581361</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.165441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.747109</td>\n",
              "      <td>0.320323</td>\n",
              "      <td>0.761069</td>\n",
              "      <td>0.653589</td>\n",
              "      <td>0.309179</td>\n",
              "      <td>0.353303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>0.729846</td>\n",
              "      <td>0.120325</td>\n",
              "      <td>0.776119</td>\n",
              "      <td>0.644310</td>\n",
              "      <td>0.080460</td>\n",
              "      <td>0.209765</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                F1 Score(toxic)  ...  F1 Score(identity_hate)\n",
              "Log Regression         0.723269  ...                 0.287648\n",
              "KNN                    0.445968  ...                 0.204668\n",
              "BernoulliNB            0.341392  ...                 0.117614\n",
              "MultinomialNB          0.653518  ...                 0.165441\n",
              "SVM                    0.747109  ...                 0.353303\n",
              "Random Forest          0.729846  ...                 0.209765\n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9wGPylU8Kv7"
      },
      "source": [
        "# Sk-multilearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0vFnOBQFsIx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e7656dae-5a04-4048-d619-04ad2d6d1db0"
      },
      "source": [
        "!pip install scikit-multilearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-multilearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/1f/e6ff649c72a1cdf2c7a1d31eb21705110ce1c5d3e7e26b2cc300e1637272/scikit_multilearn-0.2.0-py3-none-any.whl (89kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 2.6MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJp6r-X3DrqD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e19185ee-c02e-4802-db7d-2fba00271893"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve, fbeta_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "labels = ['toxic', 'severe_toxic', 'obscene', 'insult', 'threat', 'identity_hate']\n",
        "\n",
        "# train and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_train, df_train[labels], test_size=0.3, random_state=42)\n",
        "\n",
        "# Vectorize X_train, X_test\n",
        "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,1), norm='l2', max_features=5000)\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train['lemmatize_text']) # note that X_train is converted into a \"sparse matrix\"\n",
        "X_test_vectorized = vectorizer.transform(X_test['lemmatize_text']) # note that for new comments, we also need to transform them into sparse matrix before prediction\n",
        "\n",
        "# initialize LabelPowerset multi-label classifier with a RandomForest\n",
        "LogReg_pipeline = Pipeline([\n",
        "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)), # 'clf' is just the name of the OneVsRestClassifier\n",
        "            ])\n",
        "\n",
        "# train\n",
        "for label in labels:\n",
        "  print('**Processing {} comments...**'.format(label))\n",
        "  LogReg_pipeline.fit(X_train_vectorized, y_train[label])\n",
        "  prediction = LogReg_pipeline.predict(X_test_vectorized)\n",
        "\n",
        "  print('Test accuracy is {}'.format(accuracy_score(y_test[label], prediction)))\n",
        "  print('F1 score is {}'.format(f1_score(y_test[label], prediction)))\n",
        "  print('Confusion matrix: \\n', confusion_matrix(y_test[label], prediction))\n",
        "  print('roc_auc_score: \\n', roc_auc_score(y_test[label], prediction))\n",
        "  print(\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**Processing toxic comments...**\n",
            "Test accuracy is 0.955276570855615\n",
            "F1 score is 0.7153304081904003\n",
            "Confusion matrix: \n",
            " [[43041   249]\n",
            " [ 1892  2690]]\n",
            "roc_auc_score: \n",
            " 0.7906639860153609\n",
            "\n",
            "\n",
            "**Processing severe_toxic comments...**\n",
            "Test accuracy is 0.9904954879679144\n",
            "F1 score is 0.341534008683068\n",
            "Confusion matrix: \n",
            " [[47299    87]\n",
            " [  368   118]]\n",
            "roc_auc_score: \n",
            " 0.6204811842986737\n",
            "\n",
            "\n",
            "**Processing obscene comments...**\n",
            "Test accuracy is 0.9756433823529411\n",
            "F1 score is 0.7247403210576016\n",
            "Confusion matrix: \n",
            " [[45171   145]\n",
            " [ 1021  1535]]\n",
            "roc_auc_score: \n",
            " 0.7986739889913722\n",
            "\n",
            "\n",
            "**Processing insult comments...**\n",
            "Test accuracy is 0.9688335561497327\n",
            "F1 score is 0.6071616640337019\n",
            "Confusion matrix: \n",
            " [[45227   256]\n",
            " [ 1236  1153]]\n",
            "roc_auc_score: \n",
            " 0.7385001191849132\n",
            "\n",
            "\n",
            "**Processing threat comments...**\n",
            "Test accuracy is 0.9973888703208557\n",
            "F1 score is 0.2038216560509554\n",
            "Confusion matrix: \n",
            " [[47731     5]\n",
            " [  120    16]]\n",
            "roc_auc_score: \n",
            " 0.558771158035864\n",
            "\n",
            "\n",
            "**Processing identity_hate comments...**\n",
            "Test accuracy is 0.991915942513369\n",
            "F1 score is 0.2656546489563567\n",
            "Confusion matrix: \n",
            " [[47415    25]\n",
            " [  362    70]]\n",
            "roc_auc_score: \n",
            " 0.5807550277933919\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZq4wPMaI-9N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d8852299-36d2-41e5-e4f2-a0bca5e96916"
      },
      "source": [
        "X_train_vectorized"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<111699x50000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 2760464 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXrVPxaoKNl7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "37f4dde2-53e1-41e9-b863-3c43f20c0802"
      },
      "source": [
        "X_train[X_train['severe_toxic'] == 1]['lemmatize_text'].iloc[3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'need verifiable source statement check user page fat miserable balding fuck'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRDfPhm7HMpk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3bad75c5-d0c5-4edf-b0de-b615d1216db7"
      },
      "source": [
        "X_test[X_test['severe_toxic'] == 1]['lemmatize_text'].iloc[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'motherfucking assholesuck dickyou dirty son whore'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-MQMMgTAyxx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "4cdc19d9-7694-4b2a-fbe3-02b68b08fe11"
      },
      "source": [
        "test_sentences = ['stupid shit', 'suck dikkkkk suck dikkkkk gogo gogo give blowjob demand', 'motherfucking assholesuck dickyou dirty son whore', 'becasue asshole cunt fucking asshole whimsical reverts legitimate addition biased nature go fuck pathetic existence']\n",
        "test_sentences = pd.Series(test_sentences)\n",
        "test = vectorizer.transform(test_sentences)  # convert sentence into sparse matrix\n",
        "\n",
        "# visualize the sparse matrix\n",
        "import scipy.sparse\n",
        "pd.DataFrame.sparse.from_spmatrix(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>49960</th>\n",
              "      <th>49961</th>\n",
              "      <th>49962</th>\n",
              "      <th>49963</th>\n",
              "      <th>49964</th>\n",
              "      <th>49965</th>\n",
              "      <th>49966</th>\n",
              "      <th>49967</th>\n",
              "      <th>49968</th>\n",
              "      <th>49969</th>\n",
              "      <th>49970</th>\n",
              "      <th>49971</th>\n",
              "      <th>49972</th>\n",
              "      <th>49973</th>\n",
              "      <th>49974</th>\n",
              "      <th>49975</th>\n",
              "      <th>49976</th>\n",
              "      <th>49977</th>\n",
              "      <th>49978</th>\n",
              "      <th>49979</th>\n",
              "      <th>49980</th>\n",
              "      <th>49981</th>\n",
              "      <th>49982</th>\n",
              "      <th>49983</th>\n",
              "      <th>49984</th>\n",
              "      <th>49985</th>\n",
              "      <th>49986</th>\n",
              "      <th>49987</th>\n",
              "      <th>49988</th>\n",
              "      <th>49989</th>\n",
              "      <th>49990</th>\n",
              "      <th>49991</th>\n",
              "      <th>49992</th>\n",
              "      <th>49993</th>\n",
              "      <th>49994</th>\n",
              "      <th>49995</th>\n",
              "      <th>49996</th>\n",
              "      <th>49997</th>\n",
              "      <th>49998</th>\n",
              "      <th>49999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 50000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0      1      2      3      4      ...  49995  49996  49997  49998  49999\n",
              "0    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "1    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "2    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "3    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "\n",
              "[4 rows x 50000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUqBBTYqEuU3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc520e45-3ddc-4527-ed88-ea28148639fe"
      },
      "source": [
        "LogReg_pipeline.fit(X_train_vectorized, y_train['toxic']) # logreg fit on y_train['toxic']\n",
        "LogReg_pipeline.predict(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q47YF4XrFVL1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7bc59d5-8b05-4831-8fdd-e95774911fb7"
      },
      "source": [
        "LogReg_pipeline.fit(X_train_vectorized, y_train['threat']) # logreg fit on y_train['toxic']\n",
        "LogReg_pipeline.predict(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW6wHYV4F39X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed771163-7d0d-485d-cfc4-628bf915160a"
      },
      "source": [
        "LogReg_pipeline.fit(X_train_vectorized, y_train['severe_toxic']) # logreg fit on y_train['severe_toxic']\n",
        "LogReg_pipeline.predict(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKSBiRLLoQbt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wwssUhf7GeB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c073b77-6709-44b0-b45c-2e6959b487b7"
      },
      "source": [
        "train_data_randomized = train_data.loc[np.random.choice(train_data.index, size=10000)]\n",
        "train_data_randomized"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>stopwords_removed</th>\n",
              "      <th>combined_postag_wnet</th>\n",
              "      <th>lemmatize_word_w_pos</th>\n",
              "      <th>lemmatize_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>55053</th>\n",
              "      <td>931f2f3f650f11a9</td>\n",
              "      <td>Your work will be deleted or bastardized wheth...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>your work will be deleted or bastardized wheth...</td>\n",
              "      <td>[your, work, will, be, deleted, or, bastardize...</td>\n",
              "      <td>[work, deleted, bastardized, whether, adheres,...</td>\n",
              "      <td>[(work, n), (deleted, n), (bastardized, n), (w...</td>\n",
              "      <td>[work, deleted, bastardized, whether, adheres,...</td>\n",
              "      <td>work deleted bastardized whether adheres curre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138398</th>\n",
              "      <td>e46f37bdecf445f9</td>\n",
              "      <td>Are you a deaf idiot? He BROKE the bird's neck...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>are you a deaf idiot he broke the birds neck t...</td>\n",
              "      <td>[are, you, a, deaf, idiot, he, broke, the, bir...</td>\n",
              "      <td>[deaf, idiot, broke, birds, neck, sound, clear...</td>\n",
              "      <td>[(deaf, a), (idiot, n), (broke, v), (birds, n)...</td>\n",
              "      <td>[deaf, idiot, break, bird, neck, sound, clearl...</td>\n",
              "      <td>deaf idiot break bird neck sound clearly show ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12107</th>\n",
              "      <td>200bce8d97ac29e1</td>\n",
              "      <td>Well, again you are deleting my part (sourced)...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>well again you are deleting my part sourced yo...</td>\n",
              "      <td>[well, again, you, are, deleting, my, part, so...</td>\n",
              "      <td>[well, deleting, part, sourced, also, forgot, ...</td>\n",
              "      <td>[(well, r), (deleting, n), (part, n), (sourced...</td>\n",
              "      <td>[well, deleting, part, sourced, also, forgot, ...</td>\n",
              "      <td>well deleting part sourced also forgot put int...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2839</th>\n",
              "      <td>07a72f0b59459a3f</td>\n",
              "      <td>Yea. I was sort of the local shit disturber in...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>yea i was sort of the local shit disturber in ...</td>\n",
              "      <td>[yea, i, was, sort, of, the, local, shit, dist...</td>\n",
              "      <td>[yea, sort, local, shit, disturber, young, adu...</td>\n",
              "      <td>[(yea, n), (sort, n), (local, n), (shit, n), (...</td>\n",
              "      <td>[yea, sort, local, shit, disturber, young, adu...</td>\n",
              "      <td>yea sort local shit disturber young adult life...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14872</th>\n",
              "      <td>274f5a6fde5aaa56</td>\n",
              "      <td>Yes, thats right, use your admin power to disp...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>yes that is right use your admin power to disp...</td>\n",
              "      <td>[yes, that, is, right, use, your, admin, power...</td>\n",
              "      <td>[yes, right, use, admin, power, dispose, real,...</td>\n",
              "      <td>[(yes, n), (right, n), (use, v), (admin, n), (...</td>\n",
              "      <td>[yes, right, use, admin, power, dispose, real,...</td>\n",
              "      <td>yes right use admin power dispose real threat ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63341</th>\n",
              "      <td>a97b17c1944abad6</td>\n",
              "      <td>Do me a favor...\\n\\nDrop dead, and don't accus...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>do me a  drop dead and do not accuse people of...</td>\n",
              "      <td>[do, me, a, drop, dead, and, do, not, accuse, ...</td>\n",
              "      <td>[drop, dead, accuse, people, fabricating, thin...</td>\n",
              "      <td>[(drop, n), (dead, a), (accuse, v), (people, n...</td>\n",
              "      <td>[drop, dead, accuse, people, fabricating, thin...</td>\n",
              "      <td>drop dead accuse people fabricating thing okay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11842</th>\n",
              "      <td>1f572f3585453038</td>\n",
              "      <td>Applicability to Wikipedia \\n\\nTo what degree ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>applicability to wikipedia to what degree if a...</td>\n",
              "      <td>[applicability, to, wikipedia, to, what, degre...</td>\n",
              "      <td>[applicability, wikipedia, degree, apply, wiki...</td>\n",
              "      <td>[(applicability, n), (wikipedia, n), (degree, ...</td>\n",
              "      <td>[applicability, wikipedia, degree, apply, wiki...</td>\n",
              "      <td>applicability wikipedia degree apply wikipedia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159312</th>\n",
              "      <td>fbf20e312cd4a78d</td>\n",
              "      <td>Walter Mercado \\n\\nAntonio, quite frankly, you...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>walter mercado antonio quite frankly you are a...</td>\n",
              "      <td>[walter, mercado, antonio, quite, frankly, you...</td>\n",
              "      <td>[walter, mercado, antonio, quite, frankly, fuc...</td>\n",
              "      <td>[(walter, n), (mercado, n), (antonio, n), (qui...</td>\n",
              "      <td>[walter, mercado, antonio, quite, frankly, fuc...</td>\n",
              "      <td>walter mercado antonio quite frankly fucker co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11096</th>\n",
              "      <td>1d51e5c20edfe817</td>\n",
              "      <td>You're not the only one who's surprised that s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>you are not the only one who is surprised that...</td>\n",
              "      <td>[you, are, not, the, only, one, who, is, surpr...</td>\n",
              "      <td>[one, surprised, someone, died, death]</td>\n",
              "      <td>[(one, n), (surprised, v), (someone, n), (died...</td>\n",
              "      <td>[one, surprise, someone, die, death]</td>\n",
              "      <td>one surprise someone die death</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147355</th>\n",
              "      <td>3b244c81a3bdad92</td>\n",
              "      <td>burtalbert you fucking suck dick u king asshole</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>burtalbert you fucking suck dick you king asshole</td>\n",
              "      <td>[burtalbert, you, fucking, suck, dick, you, ki...</td>\n",
              "      <td>[burtalbert, fucking, suck, dick, king, asshole]</td>\n",
              "      <td>[(burtalbert, n), (fucking, n), (suck, n), (di...</td>\n",
              "      <td>[burtalbert, fucking, suck, dick, king, asshole]</td>\n",
              "      <td>burtalbert fucking suck dick king asshole</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ...                                     lemmatize_text\n",
              "55053   931f2f3f650f11a9  ...  work deleted bastardized whether adheres curre...\n",
              "138398  e46f37bdecf445f9  ...  deaf idiot break bird neck sound clearly show ...\n",
              "12107   200bce8d97ac29e1  ...  well deleting part sourced also forgot put int...\n",
              "2839    07a72f0b59459a3f  ...  yea sort local shit disturber young adult life...\n",
              "14872   274f5a6fde5aaa56  ...  yes right use admin power dispose real threat ...\n",
              "...                  ...  ...                                                ...\n",
              "63341   a97b17c1944abad6  ...     drop dead accuse people fabricating thing okay\n",
              "11842   1f572f3585453038  ...  applicability wikipedia degree apply wikipedia...\n",
              "159312  fbf20e312cd4a78d  ...  walter mercado antonio quite frankly fucker co...\n",
              "11096   1d51e5c20edfe817  ...                     one surprise someone die death\n",
              "147355  3b244c81a3bdad92  ...          burtalbert fucking suck dick king asshole\n",
              "\n",
              "[10000 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ4zj2YRoonV"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "labels = ['toxic', 'severe_toxic', 'obscene', 'insult', 'threat', 'identity_hate']\n",
        "\n",
        "# train and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_train, df_train[labels], test_size=0.3, random_state=42)\n",
        "\n",
        "# Vectorize X_train, X_test\n",
        "vectorizer = TfidfVectorizer(max_features=30000, strip_accents='unicode', analyzer='word', ngram_range=(1,1), norm='l2', stop_words='english')\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train['lemmatize_text']) # note that X_train is converted into a \"sparse matrix\"\n",
        "X_test_vectorized = vectorizer.transform(X_test['lemmatize_text']) # note that for new comments, we also need to transform them into sparse matrix before prediction\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_6RTACHEHZH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "84a921c6-022a-4bac-d8ce-ea1994d5a3d5"
      },
      "source": [
        "X_train_vectorized"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<111699x30000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 2331300 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4q-ZJPHBCKp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "outputId": "8e2eb2ab-211d-433d-acb4-5fb100e488f4"
      },
      "source": [
        "from yellowbrick.text import FreqDistVisualizer\n",
        "features = vectorizer.get_feature_names()\n",
        "visualizer = FreqDistVisualizer(features=features, orient='v')\n",
        "visualizer.fit(X_train_vectorized)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrequencyVisualizer(ax=<matplotlib.axes._subplots.AxesSubplot object at 0x7fdb2bdc5d68>,\n",
              "                    color=None,\n",
              "                    features=['aa', 'aaa', 'aah', 'aaliyah', 'aap', 'aaps',\n",
              "                              'aardvark', 'aaron', 'aau', 'aave', 'ab', 'aba',\n",
              "                              'abad', 'abandon', 'abandoning', 'abandonment',\n",
              "                              'abb', 'abbas', 'abbey', 'abbott', 'abbreviate',\n",
              "                              'abbreviated', 'abbreviation', 'abby', 'abc',\n",
              "                              'abcde', 'abd', 'abdication', 'abds', 'abducted', ...],\n",
              "                    n=None, orient='v')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0oCeV5UGqtv"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, hamming_loss\n",
        "\n",
        "ModelsPerformance = {}\n",
        "\n",
        "def metricsReport(modelName, test_labels, predictions):\n",
        "    accuracy = accuracy_score(test_labels, predictions)\n",
        "\n",
        "    macro_precision = precision_score(test_labels, predictions, average='macro')\n",
        "    macro_recall = recall_score(test_labels, predictions, average='macro')\n",
        "    macro_f1 = f1_score(test_labels, predictions, average='macro')\n",
        "\n",
        "    micro_precision = precision_score(test_labels, predictions, average='micro')\n",
        "    micro_recall = recall_score(test_labels, predictions, average='micro')\n",
        "    micro_f1 = f1_score(test_labels, predictions, average='micro')\n",
        "    hamLoss = hamming_loss(test_labels, predictions)\n",
        "    print(\"------\" + modelName + \" Model Metrics-----\")\n",
        "    print(\"Accuracy: {:.4f}\\nHamming Loss: {:.4f}\\nPrecision:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\\nRecall:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\\nF1-measure:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\"\\\n",
        "          .format(accuracy, hamLoss, macro_precision, micro_precision, macro_recall, micro_recall, macro_f1, micro_f1))\n",
        "    ModelsPerformance[modelName] = micro_f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQPv7C1tGtkv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "7d13c7db-cf54-46ea-9267-0cb87a0565cc"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "knnClf = KNeighborsClassifier()\n",
        "\n",
        "knnClf.fit(X_train_vectorized, y_train)\n",
        "knnPredictions = knnClf.predict(X_test_vectorized)\n",
        "metricsReport(\"knn\", y_test, knnPredictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------knn Model Metrics-----\n",
            "Accuracy: 0.8999\n",
            "Hamming Loss: 0.0313\n",
            "Precision:\n",
            "  - Macro: 0.6823\n",
            "  - Micro: 0.7661\n",
            "Recall:\n",
            "  - Macro: 0.1571\n",
            "  - Micro: 0.2155\n",
            "F1-measure:\n",
            "  - Macro: 0.2503\n",
            "  - Micro: 0.3364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbqNvO_ejaDA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3c42064e-cff5-4b17-87bf-f282003312b7"
      },
      "source": [
        "X_train_vectorized"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<111699x50000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 2376567 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzVXfQ3bji-P"
      },
      "source": [
        "## Dimensionality reduction?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_4gNsYPjKOI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "06bee628-b973-493d-e2bd-e5f770ec0fc7"
      },
      "source": [
        "knnClf.predict(X_test_vectorized)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzOdDEqQG9NZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "92292cc1-18c7-4b31-d045-f108356afe82"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtClassifier = DecisionTreeClassifier()\n",
        "dtClassifier.fit(X_train_vectorized, y_train)\n",
        "dtPreds = dtClassifier.predict(X_test_vectorized)\n",
        "metricsReport(\"Decision Tree\", y_test, dtPreds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------Decision Tree Model Metrics-----\n",
            "Accuracy: 0.8965\n",
            "Hamming Loss: 0.0254\n",
            "Precision:\n",
            "  - Macro: 0.5264\n",
            "  - Micro: 0.6717\n",
            "Recall:\n",
            "  - Macro: 0.4353\n",
            "  - Micro: 0.6057\n",
            "F1-measure:\n",
            "  - Macro: 0.4726\n",
            "  - Micro: 0.6370\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfeTxRMRKUV5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "7bc4999f-d407-4a77-ff5d-5961a488d3f1"
      },
      "source": [
        "dtClassifier.predict_proba(X_test_vectorized)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        ...,\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.]]), array([[1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        ...,\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.]]), array([[1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        ...,\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.]]), array([[1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        ...,\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.]]), array([[1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        ...,\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.]]), array([[1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        ...,\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U79j2VkHHXCf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "d3dd5069-7c69-4af1-fa51-0ed3c74211ad"
      },
      "source": [
        "X_test[['comment_text', 'lemmatize_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>lemmatize_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>119105</th>\n",
              "      <td>Geez, are you forgetful!  We've already discus...</td>\n",
              "      <td>geez forgetful already discuss marx anarchist ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131631</th>\n",
              "      <td>Carioca RFA \\n\\nThanks for your support on my ...</td>\n",
              "      <td>carioca rfa thanks support request adminship f...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125326</th>\n",
              "      <td>\"\\n\\n Birthday \\n\\nNo worries, It's what I do ...</td>\n",
              "      <td>birthday worry enjoy ur daytalke</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111256</th>\n",
              "      <td>Pseudoscience category? \\n\\nI'm assuming that ...</td>\n",
              "      <td>pseudoscience category assuming article pseudo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83590</th>\n",
              "      <td>(and if such phrase exists, it would be provid...</td>\n",
              "      <td>phrase exists would provide search engine even...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61999</th>\n",
              "      <td>\"\\n\\n His documented emotional involvements wi...</td>\n",
              "      <td>documented emotional involvement boy exclusion...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116777</th>\n",
              "      <td>Rename\\n\\nI don't know if it has been done or ...</td>\n",
              "      <td>rename know propose past article may renamed t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134143</th>\n",
              "      <td>Just random nazi soldiers?</td>\n",
              "      <td>random nazi soldier</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81360</th>\n",
              "      <td>add comments below this line&gt;</td>\n",
              "      <td>add comment line</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145904</th>\n",
              "      <td>Hi ur are free to add pictures and details</td>\n",
              "      <td>hi ur free add picture detail</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47872 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment_text  ... identity_hate\n",
              "119105  Geez, are you forgetful!  We've already discus...  ...             0\n",
              "131631  Carioca RFA \\n\\nThanks for your support on my ...  ...             0\n",
              "125326  \"\\n\\n Birthday \\n\\nNo worries, It's what I do ...  ...             0\n",
              "111256  Pseudoscience category? \\n\\nI'm assuming that ...  ...             0\n",
              "83590   (and if such phrase exists, it would be provid...  ...             0\n",
              "...                                                   ...  ...           ...\n",
              "61999   \"\\n\\n His documented emotional involvements wi...  ...             0\n",
              "116777  Rename\\n\\nI don't know if it has been done or ...  ...             0\n",
              "134143                         Just random nazi soldiers?  ...             0\n",
              "81360                       add comments below this line>  ...             0\n",
              "145904         Hi ur are free to add pictures and details  ...             0\n",
              "\n",
              "[47872 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNZ3fTz9HEZp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df4821c4-b46d-4e51-9c31-fcec8dbbff11"
      },
      "source": [
        "test = ['arrogant administrator homosexual bastard fuck\t']\n",
        "test = vectorizer.transform(test)\n",
        "dtClassifier.predict(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1, 1, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-_v0BwC_JnW"
      },
      "source": [
        "# X_train_vectorized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPCxjxJpJ3La",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b33c95cb-d94b-4976-b847-3cc52c51275c"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "svmClassifier = OneVsRestClassifier(LinearSVC(), n_jobs=-1)\n",
        "svmClassifier.fit(X_train_vectorized, y_train)\n",
        "\n",
        "svmPreds = svmClassifier.predict(X_test_vectorized)\n",
        "metricsReport(\"SVC Sq. Hinge Loss\", y_test, svmPreds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------SVC Sq. Hinge Loss Model Metrics-----\n",
            "Accuracy: 0.9173\n",
            "Hamming Loss: 0.0191\n",
            "Precision:\n",
            "  - Macro: 0.7133\n",
            "  - Micro: 0.8323\n",
            "Recall:\n",
            "  - Macro: 0.4348\n",
            "  - Micro: 0.6047\n",
            "F1-measure:\n",
            "  - Macro: 0.5284\n",
            "  - Micro: 0.7005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmvNCO65KFDb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e1baabb-254c-4613-e916-6aa879fe0f3e"
      },
      "source": [
        "test = ['arrogant administrator homosexual bastard fuck\t']\n",
        "\n",
        "test = vectorizer.transform(test)\n",
        "svmClassifier.predict(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1, 1, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cunNS10XL0SO"
      },
      "source": [
        "from skmultilearn.problem_transform import LabelPowerset\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "\n",
        "powerSetSVC = LabelPowerset(LinearSVC())\n",
        "powerSetSVC.fit(X_train_vectorized, y_train)\n",
        "\n",
        "powerSetSVCPreds = powerSetSVC.predict(X_test_vectorized)\n",
        "metricsReport(\"Power Set SVC\", y_test, powerSetSVCPreds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4jAhRIEhvG2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e59a7835-efc2-4122-f80b-3a2517d4e535"
      },
      "source": [
        "accuracy_score(y_test, pd.DataFrame.sparse.from_spmatrix(powerSetSVCPreds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6311248073959939"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFA4EWvPNmVw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d874310d-c0d3-42c3-84d5-134776af2a8f"
      },
      "source": [
        "powerSetSVCPreds.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs01Q5xpNrIV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b450720-2f71-46ab-cd15-74835d73cce1"
      },
      "source": [
        "test = ['arrogant administrator homosexual bastard fuck\t']\n",
        "\n",
        "test = vectorizer.transform(test)\n",
        "powerSetSVC.predict(test).toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1, 1, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-PlG2_2LrmM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ed8bc2eb-5497-47b9-c492-2137bc97c772"
      },
      "source": [
        "%%time\n",
        "\n",
        "# using binary relevance\n",
        "from sklearn.multioutput import ClassifierChain\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.2 ms, sys: 6.02 ms, total: 7.21 ms\n",
            "Wall time: 2.79 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doe7eqkKJunc"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_train, df_train[labels], test_size=0.3, random_state=42)\n",
        "\n",
        "# Vectorize X_train, X_test\n",
        "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,2), norm='l2', max_features=50000)\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train['lemmatize_text']) # note that X_train is converted into a \"sparse matrix\"\n",
        "X_test_vectorized = vectorizer.transform(X_test['lemmatize_text']) # note that for new comments, we also need to transform them into sparse matrix before prediction\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUgdr9OdPGcV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7ef013c-2fe9-403a-9267-1ecc6ed92f4f"
      },
      "source": [
        "# initialize binary relevance multi-label classifier\n",
        "# with a gaussian naive bayes base classifier\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.multioutput import ClassifierChain\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "base_lr = LogisticRegression()\n",
        "\n",
        "ovr = OneVsRestClassifier(base_lr)\n",
        "ovr.fit(X_train_vectorized, y_train)\n",
        "Y_pred_ovr = ovr.predict(X_test_vectorized)\n",
        "ovr_jaccard_score = jaccard_score(y_test, Y_pred_ovr, average='samples')\n",
        "\n",
        "\n",
        "chains = [ClassifierChain(base_lr, random_state=i)\n",
        "          for i in range(6)]\n",
        "for chain in chains:\n",
        "    chain.fit(X_train_vectorized, y_train)\n",
        "\n",
        "Y_pred_chains = np.array([chain.predict(X_test_vectorized) for chain in\n",
        "                          chains])\n",
        "\n",
        "chain_jaccard_scores = [jaccard_score(y_test, Y_pred_chain >= .5,\n",
        "                                      average='samples')\n",
        "                        for Y_pred_chain in Y_pred_chains]\n",
        "\n",
        "Y_pred_ensemble = Y_pred_chains.mean(axis=0)\n",
        "ensemble_jaccard_score = jaccard_score(y_test,\n",
        "                                       Y_pred_ensemble >= .5,\n",
        "                                       average='samples')\n",
        "\n",
        "model_scores = [ovr_jaccard_score] + chain_jaccard_scores\n",
        "model_scores.append(ensemble_jaccard_score)\n",
        "\n",
        "model_names = ('Independent',\n",
        "               'Chain 1',\n",
        "               'Chain 2',\n",
        "               'Chain 3',\n",
        "               'Chain 4',\n",
        "               'Chain 5',\n",
        "               'Chain 6',\n",
        "               'Ensemble')\n",
        "\n",
        "x_pos = np.arange(len(model_names))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 4))\n",
        "ax.grid(True)\n",
        "ax.set_title('Classifier Chain Ensemble Performance Comparison')\n",
        "ax.set_xticks(x_pos)\n",
        "ax.set_xticklabels(model_names, rotation='vertical')\n",
        "ax.set_ylabel('Jaccard Similarity Score')\n",
        "ax.set_ylim([min(model_scores) * .9, max(model_scores) * 1.1])\n",
        "colors = ['r'] + ['b'] * len(chain_jaccard_scores) + ['g']\n",
        "ax.bar(x_pos, model_scores, alpha=0.5, color=colors)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSTmIBhi9kvL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "outputId": "3f5ff9de-40d9-4a47-bce7-e5c99f573394"
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>stopwords_removed</th>\n",
              "      <th>combined_postag_wnet</th>\n",
              "      <th>lemmatize_word_w_pos</th>\n",
              "      <th>lemmatize_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>119105</th>\n",
              "      <td>7ca72b5b9c688e9e</td>\n",
              "      <td>Geez, are you forgetful!  We've already discus...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>geez are you forgetful we have already discuss...</td>\n",
              "      <td>[geez, are, you, forgetful, we, have, already,...</td>\n",
              "      <td>[geez, forgetful, already, discussed, marx, an...</td>\n",
              "      <td>[(geez, n), (forgetful, n), (already, r), (dis...</td>\n",
              "      <td>[geez, forgetful, already, discuss, marx, anar...</td>\n",
              "      <td>geez forgetful already discuss marx anarchist ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131631</th>\n",
              "      <td>c03f72fd8f8bf54f</td>\n",
              "      <td>Carioca RFA \\n\\nThanks for your support on my ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>carioca rfa thanks for your support on my requ...</td>\n",
              "      <td>[carioca, rfa, thanks, for, your, support, on,...</td>\n",
              "      <td>[carioca, rfa, thanks, support, request, admin...</td>\n",
              "      <td>[(carioca, n), (rfa, n), (thanks, n), (support...</td>\n",
              "      <td>[carioca, rfa, thanks, support, request, admin...</td>\n",
              "      <td>carioca rfa thanks support request adminship f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125326</th>\n",
              "      <td>9e5b8e8fc1ff2e84</td>\n",
              "      <td>\"\\n\\n Birthday \\n\\nNo worries, It's what I do ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>birthday no worries it is what i do enjoy ur ...</td>\n",
              "      <td>[birthday, no, worries, it, is, what, i, do, e...</td>\n",
              "      <td>[birthday, worries, enjoy, ur, daytalke]</td>\n",
              "      <td>[(birthday, n), (worries, n), (enjoy, v), (ur,...</td>\n",
              "      <td>[birthday, worry, enjoy, ur, daytalke]</td>\n",
              "      <td>birthday worry enjoy ur daytalke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111256</th>\n",
              "      <td>5332799e706665a6</td>\n",
              "      <td>Pseudoscience category? \\n\\nI'm assuming that ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>pseudoscience category i am assuming that this...</td>\n",
              "      <td>[pseudoscience, category, i, am, assuming, tha...</td>\n",
              "      <td>[pseudoscience, category, assuming, article, p...</td>\n",
              "      <td>[(pseudoscience, n), (category, n), (assuming,...</td>\n",
              "      <td>[pseudoscience, category, assuming, article, p...</td>\n",
              "      <td>pseudoscience category assuming article pseudo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83590</th>\n",
              "      <td>dfa7d8f0b4366680</td>\n",
              "      <td>(and if such phrase exists, it would be provid...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>and if such phrase exists it would be provided...</td>\n",
              "      <td>[and, if, such, phrase, exists, it, would, be,...</td>\n",
              "      <td>[phrase, exists, would, provided, search, engi...</td>\n",
              "      <td>[(phrase, n), (exists, n), (would, n), (provid...</td>\n",
              "      <td>[phrase, exists, would, provide, search, engin...</td>\n",
              "      <td>phrase exists would provide search engine even...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61999</th>\n",
              "      <td>a5e8811002c2e965</td>\n",
              "      <td>\"\\n\\n His documented emotional involvements wi...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>his documented emotional involvements with bo...</td>\n",
              "      <td>[his, documented, emotional, involvements, wit...</td>\n",
              "      <td>[documented, emotional, involvements, boys, ex...</td>\n",
              "      <td>[(documented, n), (emotional, n), (involvement...</td>\n",
              "      <td>[documented, emotional, involvement, boy, excl...</td>\n",
              "      <td>documented emotional involvement boy exclusion...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116777</th>\n",
              "      <td>703c79bd1ef1f61d</td>\n",
              "      <td>Rename\\n\\nI don't know if it has been done or ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>rename i do not know if it has been done or pr...</td>\n",
              "      <td>[rename, i, do, not, know, if, it, has, been, ...</td>\n",
              "      <td>[rename, know, done, proposed, past, article, ...</td>\n",
              "      <td>[(rename, n), (know, v), (done, v), (proposed,...</td>\n",
              "      <td>[rename, know, propose, past, article, may, re...</td>\n",
              "      <td>rename know propose past article may renamed t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134143</th>\n",
              "      <td>cd618fa54e2da21d</td>\n",
              "      <td>Just random nazi soldiers?</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>just random nazi soldiers</td>\n",
              "      <td>[just, random, nazi, soldiers]</td>\n",
              "      <td>[random, nazi, soldiers]</td>\n",
              "      <td>[(random, n), (nazi, n), (soldiers, n)]</td>\n",
              "      <td>[random, nazi, soldier]</td>\n",
              "      <td>random nazi soldier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81360</th>\n",
              "      <td>d99ec9d910520101</td>\n",
              "      <td>add comments below this line&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>add comments below this line</td>\n",
              "      <td>[add, comments, below, this, line]</td>\n",
              "      <td>[add, comments, line]</td>\n",
              "      <td>[(add, v), (comments, n), (line, n)]</td>\n",
              "      <td>[add, comment, line]</td>\n",
              "      <td>add comment line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145904</th>\n",
              "      <td>23f6d004bfd9ed1d</td>\n",
              "      <td>Hi ur are free to add pictures and details</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>hi ur are free to add pictures and details</td>\n",
              "      <td>[hi, ur, are, free, to, add, pictures, and, de...</td>\n",
              "      <td>[hi, ur, free, add, pictures, details]</td>\n",
              "      <td>[(hi, n), (ur, n), (free, a), (add, v), (pictu...</td>\n",
              "      <td>[hi, ur, free, add, picture, detail]</td>\n",
              "      <td>hi ur free add picture detail</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47872 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ...                                     lemmatize_text\n",
              "119105  7ca72b5b9c688e9e  ...  geez forgetful already discuss marx anarchist ...\n",
              "131631  c03f72fd8f8bf54f  ...  carioca rfa thanks support request adminship f...\n",
              "125326  9e5b8e8fc1ff2e84  ...                   birthday worry enjoy ur daytalke\n",
              "111256  5332799e706665a6  ...  pseudoscience category assuming article pseudo...\n",
              "83590   dfa7d8f0b4366680  ...  phrase exists would provide search engine even...\n",
              "...                  ...  ...                                                ...\n",
              "61999   a5e8811002c2e965  ...  documented emotional involvement boy exclusion...\n",
              "116777  703c79bd1ef1f61d  ...  rename know propose past article may renamed t...\n",
              "134143  cd618fa54e2da21d  ...                                random nazi soldier\n",
              "81360   d99ec9d910520101  ...                                   add comment line\n",
              "145904  23f6d004bfd9ed1d  ...                      hi ur free add picture detail\n",
              "\n",
              "[47872 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcJGE2pZ9fqy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b46d83b2-1af5-4ca3-8026-7e7d449eaabe"
      },
      "source": [
        "Y_pred_ensemble"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QZs7kkt9rgy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "dbbea098-ea10-4268-a162-3ab2a04d3490"
      },
      "source": [
        "Y_pred_chains"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g_QPbtjGeDX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c3ff1ca0-8ecf-4d05-98b8-9dcfbf95411d"
      },
      "source": [
        "Y_pred_ovr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzNF3l9m96Sm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b347cb08-91f3-480c-9c33-ecef776c2727"
      },
      "source": [
        "accuracy_score(y_test, Y_pred_ovr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9172585227272727"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AEpiy3CrDif"
      },
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UEowT7CGPSr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7804acf4-446d-4eac-c261-bf6086bfd305"
      },
      "source": [
        "f1_score(y_test, Y_pred_ovr, average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6420400942359448"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC5gCB5--2TQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7c239992-43eb-4a77-a9d3-921d6ee5e284"
      },
      "source": [
        "Y_pred_ensemble"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZk5DUEJByGB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "594534e2-2be7-4e56-c6ae-f90ac1addf0f"
      },
      "source": [
        "accuracy_score(y_test, Y_pred_ensemble >= .5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9193683155080213"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVmeqdYHF5_a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c390572-b07f-4027-f53c-6bf3dbbb67e5"
      },
      "source": [
        "f1_score(y_test, Y_pred_ensemble >= 0.5, average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6616911579886408"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFF6OBjfGpBO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "be6cceb0-ac3c-47a1-d356-f1c000ad05f4"
      },
      "source": [
        "# initialize classifier chains multi-label classifier\n",
        "classifier = ClassifierChain(LogisticRegression())\n",
        "\n",
        "# Training logistic regression model on train data\n",
        "classifier.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# predict\n",
        "predictions = classifier.predict(X_test_vectorized)\n",
        "\n",
        "# accuracy\n",
        "print(\"Accuracy = \",accuracy_score(y_test,predictions))\n",
        "print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.9193683155080213\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMNFNH6rrou_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "20a0741b-2572-4668-940b-76104dde5070"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, multilabel_confusion_matrix\n",
        "\n",
        "multilabel_confusion_matrix(y_test, predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[43080,   210],\n",
              "        [ 1966,  2616]],\n",
              "\n",
              "       [[47332,    54],\n",
              "        [  416,    70]],\n",
              "\n",
              "       [[45118,   198],\n",
              "        [  889,  1667]],\n",
              "\n",
              "       [[45018,   465],\n",
              "        [  995,  1394]],\n",
              "\n",
              "       [[47731,     5],\n",
              "        [  118,    18]],\n",
              "\n",
              "       [[47427,    13],\n",
              "        [  355,    77]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALqfq28hG0Xu"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3TUdIg4HGnb"
      },
      "source": [
        "df_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2Gdrts1HRXa"
      },
      "source": [
        "# Train on the entire dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOs1XxFLQIgN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a2fd729-6f8b-4293-9822-eafaaa58d19c"
      },
      "source": [
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>stopwords_removed</th>\n",
              "      <th>combined_postag_wnet</th>\n",
              "      <th>lemmatize_word_w_pos</th>\n",
              "      <th>lemmatize_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>explanation why the edits made under my userna...</td>\n",
              "      <td>['explanation', 'why', 'the', 'edits', 'made',...</td>\n",
              "      <td>['explanation', 'edits', 'made', 'username', '...</td>\n",
              "      <td>[('explanation', 'n'), ('edits', 'n'), ('made'...</td>\n",
              "      <td>['explanation', 'edits', 'make', 'username', '...</td>\n",
              "      <td>explanation edits make username hardcore metal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>daww he matches this background colour i am se...</td>\n",
              "      <td>['daww', 'he', 'matches', 'this', 'background'...</td>\n",
              "      <td>['daww', 'matches', 'background', 'colour', 's...</td>\n",
              "      <td>[('daww', 'n'), ('matches', 'n'), ('background...</td>\n",
              "      <td>['daww', 'match', 'background', 'colour', 'see...</td>\n",
              "      <td>daww match background colour seemingly stick t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>hey man i am really not trying to edit war it ...</td>\n",
              "      <td>['hey', 'man', 'i', 'am', 'really', 'not', 'tr...</td>\n",
              "      <td>['hey', 'man', 'really', 'trying', 'edit', 'wa...</td>\n",
              "      <td>[('hey', 'n'), ('man', 'n'), ('really', 'r'), ...</td>\n",
              "      <td>['hey', 'man', 'really', 'try', 'edit', 'war',...</td>\n",
              "      <td>hey man really try edit war guy constantly rem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>more i can not make any real suggestions on i...</td>\n",
              "      <td>['more', 'i', 'can', 'not', 'make', 'any', 're...</td>\n",
              "      <td>['make', 'real', 'suggestions', 'improvement',...</td>\n",
              "      <td>[('make', 'v'), ('real', 'a'), ('suggestions',...</td>\n",
              "      <td>['make', 'real', 'suggestion', 'improvement', ...</td>\n",
              "      <td>make real suggestion improvement wondered sect...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>you sir are my hero any chance you remember wh...</td>\n",
              "      <td>['you', 'sir', 'are', 'my', 'hero', 'any', 'ch...</td>\n",
              "      <td>['sir', 'hero', 'chance', 'remember', 'page']</td>\n",
              "      <td>[('sir', 'n'), ('hero', 'n'), ('chance', 'n'),...</td>\n",
              "      <td>['sir', 'hero', 'chance', 'remember', 'page']</td>\n",
              "      <td>sir hero chance remember page</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159566</th>\n",
              "      <td>159566</td>\n",
              "      <td>ffe987279560d7ff</td>\n",
              "      <td>\":::::And for the second time of asking, when ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>and for the second time of asking when your vi...</td>\n",
              "      <td>['and', 'for', 'the', 'second', 'time', 'of', ...</td>\n",
              "      <td>['second', 'time', 'asking', 'view', 'complete...</td>\n",
              "      <td>[('second', 'n'), ('time', 'n'), ('asking', 'v...</td>\n",
              "      <td>['second', 'time', 'ask', 'view', 'completely'...</td>\n",
              "      <td>second time ask view completely contradicts co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159567</th>\n",
              "      <td>159567</td>\n",
              "      <td>ffea4adeee384e90</td>\n",
              "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>you should be ashamed of yourself that is a ho...</td>\n",
              "      <td>['you', 'should', 'be', 'ashamed', 'of', 'your...</td>\n",
              "      <td>['ashamed', 'horrible', 'thing', 'put', 'talk'...</td>\n",
              "      <td>[('ashamed', 'n'), ('horrible', 'n'), ('thing'...</td>\n",
              "      <td>['ashamed', 'horrible', 'thing', 'put', 'talk'...</td>\n",
              "      <td>ashamed horrible thing put talk page</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159568</th>\n",
              "      <td>159568</td>\n",
              "      <td>ffee36eab5c267c9</td>\n",
              "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>spitzer umm there is no actual article for pro...</td>\n",
              "      <td>['spitzer', 'umm', 'there', 'is', 'no', 'actua...</td>\n",
              "      <td>['spitzer', 'umm', 'actual', 'article', 'prost...</td>\n",
              "      <td>[('spitzer', 'n'), ('umm', 'n'), ('actual', 'a...</td>\n",
              "      <td>['spitzer', 'umm', 'actual', 'article', 'prost...</td>\n",
              "      <td>spitzer umm actual article prostitution ring c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159569</th>\n",
              "      <td>159569</td>\n",
              "      <td>fff125370e4aaaf3</td>\n",
              "      <td>And it looks like it was actually you who put ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>and it looks like it was actually you who put ...</td>\n",
              "      <td>['and', 'it', 'looks', 'like', 'it', 'was', 'a...</td>\n",
              "      <td>['looks', 'like', 'actually', 'put', 'speedy',...</td>\n",
              "      <td>[('looks', 'v'), ('like', 'n'), ('actually', '...</td>\n",
              "      <td>['look', 'like', 'actually', 'put', 'speedy', ...</td>\n",
              "      <td>look like actually put speedy first version de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159570</th>\n",
              "      <td>159570</td>\n",
              "      <td>fff46fc426af1f9a</td>\n",
              "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>and  i really do not think you understand i c...</td>\n",
              "      <td>['and', 'i', 'really', 'do', 'not', 'think', '...</td>\n",
              "      <td>['really', 'think', 'understand', 'came', 'ide...</td>\n",
              "      <td>[('really', 'r'), ('think', 'v'), ('understand...</td>\n",
              "      <td>['really', 'think', 'understand', 'come', 'ide...</td>\n",
              "      <td>really think understand come idea bad right aw...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159571 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0  ...                                     lemmatize_text\n",
              "0                0  ...  explanation edits make username hardcore metal...\n",
              "1                1  ...  daww match background colour seemingly stick t...\n",
              "2                2  ...  hey man really try edit war guy constantly rem...\n",
              "3                3  ...  make real suggestion improvement wondered sect...\n",
              "4                4  ...                      sir hero chance remember page\n",
              "...            ...  ...                                                ...\n",
              "159566      159566  ...  second time ask view completely contradicts co...\n",
              "159567      159567  ...               ashamed horrible thing put talk page\n",
              "159568      159568  ...  spitzer umm actual article prostitution ring c...\n",
              "159569      159569  ...  look like actually put speedy first version de...\n",
              "159570      159570  ...  really think understand come idea bad right aw...\n",
              "\n",
              "[159571 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quEhnO9RQNWn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e2a67608-5ce0-458f-c2b3-977926023072"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "df_train['lemmatize_comment_length'] = df_train['lemmatize_text'].apply(lambda x: len(str(x)))\n",
        "plt.figure()\n",
        "plt.hist(df_train['lemmatize_comment_length'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YYOhemjSNHH"
      },
      "source": [
        "df_train = df_train.fillna('')\n",
        "df_test = df_test.fillna('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmYKOFJrbq_L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "outputId": "1cbc75e0-2c70-460e-a879-bd2fe4238ddb"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>stopwords_removed</th>\n",
              "      <th>combined_postag_wnet</th>\n",
              "      <th>lemmatize_word_w_pos</th>\n",
              "      <th>lemmatize_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
              "      <td>yo bitch ja rule is more succesful then you wi...</td>\n",
              "      <td>['yo', 'bitch', 'ja', 'rule', 'is', 'more', 's...</td>\n",
              "      <td>['yo', 'bitch', 'ja', 'rule', 'succesful', 'ev...</td>\n",
              "      <td>[('yo', 'n'), ('bitch', 'n'), ('ja', 'n'), ('r...</td>\n",
              "      <td>['yo', 'bitch', 'ja', 'rule', 'succesful', 'ev...</td>\n",
              "      <td>yo bitch ja rule succesful ever hating sad mof...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "      <td>from rfc  the title is fine as it is in my op...</td>\n",
              "      <td>['from', 'rfc', 'the', 'title', 'is', 'fine', ...</td>\n",
              "      <td>['rfc', 'title', 'fine', 'opinion']</td>\n",
              "      <td>[('rfc', 'n'), ('title', 'n'), ('fine', 'a'), ...</td>\n",
              "      <td>['rfc', 'title', 'fine', 'opinion']</td>\n",
              "      <td>rfc title fine opinion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "      <td>sources   zawe ashton on lapland</td>\n",
              "      <td>['sources', 'zawe', 'ashton', 'on', 'lapland']</td>\n",
              "      <td>['sources', 'zawe', 'ashton', 'lapland']</td>\n",
              "      <td>[('sources', 'n'), ('zawe', 'n'), ('ashton', '...</td>\n",
              "      <td>['source', 'zawe', 'ashton', 'lapland']</td>\n",
              "      <td>source zawe ashton lapland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "      <td>if you have a look back at the source the info...</td>\n",
              "      <td>['if', 'you', 'have', 'a', 'look', 'back', 'at...</td>\n",
              "      <td>['look', 'back', 'source', 'information', 'upd...</td>\n",
              "      <td>[('look', 'v'), ('back', 'r'), ('source', 'n')...</td>\n",
              "      <td>['look', 'back', 'source', 'information', 'upd...</td>\n",
              "      <td>look back source information update correct fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>I don't anonymously edit articles at all.</td>\n",
              "      <td>i do not anonymously edit articles at all</td>\n",
              "      <td>['i', 'do', 'not', 'anonymously', 'edit', 'art...</td>\n",
              "      <td>['anonymously', 'edit', 'articles']</td>\n",
              "      <td>[('anonymously', 'n'), ('edit', 'n'), ('articl...</td>\n",
              "      <td>['anonymously', 'edit', 'article']</td>\n",
              "      <td>anonymously edit article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153159</th>\n",
              "      <td>153159</td>\n",
              "      <td>153159</td>\n",
              "      <td>fffcd0960ee309b5</td>\n",
              "      <td>. \\n i totally agree, this stuff is nothing bu...</td>\n",
              "      <td>i totally agree this stuff is nothing but too...</td>\n",
              "      <td>['i', 'totally', 'agree', 'this', 'stuff', 'is...</td>\n",
              "      <td>['totally', 'agree', 'stuff', 'nothing', 'tool...</td>\n",
              "      <td>[('totally', 'r'), ('agree', 'v'), ('stuff', '...</td>\n",
              "      <td>['totally', 'agree', 'stuff', 'nothing', 'tool...</td>\n",
              "      <td>totally agree stuff nothing toolongcrap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153160</th>\n",
              "      <td>153160</td>\n",
              "      <td>153160</td>\n",
              "      <td>fffd7a9a6eb32c16</td>\n",
              "      <td>== Throw from out field to home plate. == \\n\\n...</td>\n",
              "      <td>throw from out field to home plate  does it g...</td>\n",
              "      <td>['throw', 'from', 'out', 'field', 'to', 'home'...</td>\n",
              "      <td>['throw', 'field', 'home', 'plate', 'get', 'fa...</td>\n",
              "      <td>[('throw', 'v'), ('field', 'n'), ('home', 'n')...</td>\n",
              "      <td>['throw', 'field', 'home', 'plate', 'get', 'fa...</td>\n",
              "      <td>throw field home plate get fast throw cut man ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153161</th>\n",
              "      <td>153161</td>\n",
              "      <td>153161</td>\n",
              "      <td>fffda9e8d6fafa9e</td>\n",
              "      <td>\" \\n\\n == Okinotorishima categories == \\n\\n I ...</td>\n",
              "      <td>okinotorishima categories  i see your change...</td>\n",
              "      <td>['okinotorishima', 'categories', 'i', 'see', '...</td>\n",
              "      <td>['okinotorishima', 'categories', 'see', 'chang...</td>\n",
              "      <td>[('okinotorishima', 'n'), ('categories', 'n'),...</td>\n",
              "      <td>['okinotorishima', 'category', 'see', 'change'...</td>\n",
              "      <td>okinotorishima category see change agree corre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153162</th>\n",
              "      <td>153162</td>\n",
              "      <td>153162</td>\n",
              "      <td>fffe8f1340a79fc2</td>\n",
              "      <td>\" \\n\\n == \"\"One of the founding nations of the...</td>\n",
              "      <td>one of the founding nations of the eu  germa...</td>\n",
              "      <td>['one', 'of', 'the', 'founding', 'nations', 'o...</td>\n",
              "      <td>['one', 'founding', 'nations', 'eu', 'germany'...</td>\n",
              "      <td>[('one', 'n'), ('founding', 'v'), ('nations', ...</td>\n",
              "      <td>['one', 'found', 'nation', 'eu', 'germany', 'l...</td>\n",
              "      <td>one found nation eu germany law return quite s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153163</th>\n",
              "      <td>153163</td>\n",
              "      <td>153163</td>\n",
              "      <td>ffffce3fb183ee80</td>\n",
              "      <td>\" \\n :::Stop already. Your bullshit is not wel...</td>\n",
              "      <td>stop already your bullshit is not welcome her...</td>\n",
              "      <td>['stop', 'already', 'your', 'bullshit', 'is', ...</td>\n",
              "      <td>['stop', 'already', 'bullshit', 'welcome', 'fo...</td>\n",
              "      <td>[('stop', 'v'), ('already', 'r'), ('bullshit',...</td>\n",
              "      <td>['stop', 'already', 'bullshit', 'welcome', 'fo...</td>\n",
              "      <td>stop already bullshit welcome fool think kind ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153164 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0  ...                                     lemmatize_text\n",
              "0                0  ...  yo bitch ja rule succesful ever hating sad mof...\n",
              "1                1  ...                             rfc title fine opinion\n",
              "2                2  ...                         source zawe ashton lapland\n",
              "3                3  ...  look back source information update correct fo...\n",
              "4                4  ...                           anonymously edit article\n",
              "...            ...  ...                                                ...\n",
              "153159      153159  ...            totally agree stuff nothing toolongcrap\n",
              "153160      153160  ...  throw field home plate get fast throw cut man ...\n",
              "153161      153161  ...  okinotorishima category see change agree corre...\n",
              "153162      153162  ...  one found nation eu germany law return quite s...\n",
              "153163      153163  ...  stop already bullshit welcome fool think kind ...\n",
              "\n",
              "[153164 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LNd7YUJRe8n"
      },
      "source": [
        "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', norm='l2', max_features=10000) # ngram_range=(1,2)\n",
        "X_train_vectorized = vectorizer.fit_transform(df_train['lemmatize_text'])\n",
        "X_test_vectorized = vectorizer.transform(df_test['lemmatize_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAtwMccpcrSq"
      },
      "source": [
        "type(X_train_vectorized)\n",
        "X_train_vectorized.todense().shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOfLjV5vcsyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b14aa40-2497-4932-c0fd-83e5940cd57a"
      },
      "source": [
        "X_test_vectorized"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<153164x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 2908849 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zhjl5h2ECQP"
      },
      "source": [
        "# predict_proba for roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQGIuwFrcw51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "f89f732c-2e0f-4aa5-ea56-65f47ed8531a"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "logreg = LogisticRegression(C=12.0, max_iter=300)\n",
        "\n",
        "# create submission file\n",
        "submission_binary = pd.read_csv('/content/drive/My Drive/CS3244 Project/sample_submission.csv')\n",
        "\n",
        "columns = ['obscene','insult','toxic','severe_toxic','identity_hate','threat']\n",
        "\n",
        "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', norm='l2', max_features=5000) # ngram_range=(1,2)\n",
        "X_train_vectorized = vectorizer.fit_transform(df_train['lemmatize_text'])\n",
        "X_test_vectorized = vectorizer.transform(df_test['lemmatize_text'])\n",
        "\n",
        "for label in columns:\n",
        "    print('... Processing {}'.format(label))\n",
        "    y = df_train[label]\n",
        "    # train the model using X_dtm & y\n",
        "    logreg.fit(X_train_vectorized, y)\n",
        "    # compute the training accuracy\n",
        "    y_pred_X = logreg.predict(X_train_vectorized)\n",
        "    y_pred_proba_X = logreg.predict_proba(X_train_vectorized) [:,1]\n",
        "    print('Training accuracy is {}'.format(accuracy_score(y, y_pred_X)))\n",
        "    print('Training f1_score is {}'.format(f1_score(y, y_pred_X)))\n",
        "    print('Training roc_auc_score is {}'.format(roc_auc_score(y, y_pred_proba_X)))\n",
        "\n",
        "    # compute the predicted probabilities for X_test_dtm\n",
        "    test_y_prob = logreg.predict_proba(X_test_vectorized)[:,1]\n",
        "    submission_binary[label] = test_y_prob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "... Processing obscene\n",
            "Training accuracy is 0.9818576057052973\n",
            "Training f1_score is 0.8119274995127654\n",
            "Training roc_auc_score is 0.9888227160378774\n",
            "... Processing insult\n",
            "Training accuracy is 0.9758226745461268\n",
            "Training f1_score is 0.7236785560807907\n",
            "Training roc_auc_score is 0.984102166171212\n",
            "... Processing toxic\n",
            "Training accuracy is 0.9637026778048643\n",
            "Training f1_score is 0.789105738421206\n",
            "Training roc_auc_score is 0.9777146595538143\n",
            "... Processing severe_toxic\n",
            "Training accuracy is 0.9920348935583533\n",
            "Training f1_score is 0.4922093487814623\n",
            "Training roc_auc_score is 0.9934567875315532\n",
            "... Processing identity_hate\n",
            "Training accuracy is 0.994052804080942\n",
            "Training f1_score is 0.5620673742501153\n",
            "Training roc_auc_score is 0.992883169774825\n",
            "... Processing threat\n",
            "Training accuracy is 0.9979946230831417\n",
            "Training f1_score is 0.553072625698324\n",
            "Training roc_auc_score is 0.9984694749869599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haAKFSxXOkmA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "f2d561fc-45f2-4b81-b1f8-9cb25c69fcc3"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "logreg = LogisticRegression(C=12.0, max_iter=300)\n",
        "\n",
        "# create submission file\n",
        "submission_binary = pd.read_csv('/content/drive/My Drive/CS3244 Project/sample_submission.csv')\n",
        "\n",
        "columns = ['obscene','insult','toxic','severe_toxic','identity_hate','threat']\n",
        "\n",
        "X = df_train['lemmatize_text']\n",
        "y = df_train[columns]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
        "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', norm='l2', max_features=5000) # ngram_range=(1,2)\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "for label in columns:\n",
        "    print('... Processing {}'.format(label))\n",
        "    y_train_label = y_train[label]\n",
        "    y_test_label = y_test[label]\n",
        "    # train the model using X_dtm & y\n",
        "    logreg.fit(X_train_vectorized, y_train_label)\n",
        "    # compute the training accuracy\n",
        "    y_test_pred_X = logreg.predict(X_test_vectorized)\n",
        "    y_test_pred_proba_X = logreg.predict_proba(X_test_vectorized) [:,1]\n",
        "    print('Test accuracy is {}'.format(accuracy_score(y_test_label, y_test_pred_X)))\n",
        "    print('Test f1_score is {}'.format(f1_score(y_test_label, y_test_pred_X)))\n",
        "    print('Test roc_auc_score is {}'.format(roc_auc_score(y_test_label, y_test_pred_proba_X)))\n",
        "\n",
        "    # compute the predicted probabilities for X_test_dtm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "... Processing obscene\n",
            "Test accuracy is 0.9780038435828877\n",
            "Test f1_score is 0.7686222808174028\n",
            "Test roc_auc_score is 0.9708640493380037\n",
            "... Processing insult\n",
            "Test accuracy is 0.9707344585561497\n",
            "Test f1_score is 0.6577082824334228\n",
            "Test roc_auc_score is 0.9640924159751705\n",
            "... Processing toxic\n",
            "Test accuracy is 0.9587650401069518\n",
            "Test f1_score is 0.7567767373090193\n",
            "Test roc_auc_score is 0.9607971672698011\n",
            "... Processing severe_toxic\n",
            "Test accuracy is 0.9902865975935828\n",
            "Test f1_score is 0.3478260869565218\n",
            "Test roc_auc_score is 0.976027907606855\n",
            "... Processing identity_hate\n",
            "Test accuracy is 0.9923963903743316\n",
            "Test f1_score is 0.42767295597484273\n",
            "Test roc_auc_score is 0.9638256667477881\n",
            "... Processing threat\n",
            "Test accuracy is 0.9971799799465241\n",
            "Test f1_score is 0.33497536945812806\n",
            "Test roc_auc_score is 0.9751574751136067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUciT70rMb9x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c53e05bb-1105-45e2-d0ba-815c63eea265"
      },
      "source": [
        "logreg.predict_proba(X_train_vectorized)[:,1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.43729323e-05, 1.16832790e-04, 1.03053792e-04, ...,\n",
              "       5.80949670e-05, 8.08299300e-05, 1.96999781e-03])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFPRbPy6fM5l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "1b28aca0-d5d9-409a-9666-cf5fd4bcb069"
      },
      "source": [
        "submission_binary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>0.999664</td>\n",
              "      <td>0.196321</td>\n",
              "      <td>0.999294</td>\n",
              "      <td>0.163336</td>\n",
              "      <td>0.970496</td>\n",
              "      <td>0.239690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>0.001448</td>\n",
              "      <td>0.000560</td>\n",
              "      <td>0.000378</td>\n",
              "      <td>0.000283</td>\n",
              "      <td>0.002833</td>\n",
              "      <td>0.000757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>0.005990</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.001976</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.001816</td>\n",
              "      <td>0.000089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>0.001782</td>\n",
              "      <td>0.001891</td>\n",
              "      <td>0.001778</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.002619</td>\n",
              "      <td>0.000091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>0.012462</td>\n",
              "      <td>0.000262</td>\n",
              "      <td>0.001410</td>\n",
              "      <td>0.000348</td>\n",
              "      <td>0.002985</td>\n",
              "      <td>0.000386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153159</th>\n",
              "      <td>fffcd0960ee309b5</td>\n",
              "      <td>0.033246</td>\n",
              "      <td>0.000117</td>\n",
              "      <td>0.002090</td>\n",
              "      <td>0.000333</td>\n",
              "      <td>0.012084</td>\n",
              "      <td>0.000247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153160</th>\n",
              "      <td>fffd7a9a6eb32c16</td>\n",
              "      <td>0.038302</td>\n",
              "      <td>0.002041</td>\n",
              "      <td>0.006383</td>\n",
              "      <td>0.008475</td>\n",
              "      <td>0.017371</td>\n",
              "      <td>0.033007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153161</th>\n",
              "      <td>fffda9e8d6fafa9e</td>\n",
              "      <td>0.000974</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>0.005805</td>\n",
              "      <td>0.000212</td>\n",
              "      <td>0.001298</td>\n",
              "      <td>0.000321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153162</th>\n",
              "      <td>fffe8f1340a79fc2</td>\n",
              "      <td>0.008781</td>\n",
              "      <td>0.000976</td>\n",
              "      <td>0.021825</td>\n",
              "      <td>0.007176</td>\n",
              "      <td>0.007857</td>\n",
              "      <td>0.022365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153163</th>\n",
              "      <td>ffffce3fb183ee80</td>\n",
              "      <td>0.996695</td>\n",
              "      <td>0.000174</td>\n",
              "      <td>0.894595</td>\n",
              "      <td>0.001049</td>\n",
              "      <td>0.286736</td>\n",
              "      <td>0.001376</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153164 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id     toxic  ...    insult  identity_hate\n",
              "0       00001cee341fdb12  0.999664  ...  0.970496       0.239690\n",
              "1       0000247867823ef7  0.001448  ...  0.002833       0.000757\n",
              "2       00013b17ad220c46  0.005990  ...  0.001816       0.000089\n",
              "3       00017563c3f7919a  0.001782  ...  0.002619       0.000091\n",
              "4       00017695ad8997eb  0.012462  ...  0.002985       0.000386\n",
              "...                  ...       ...  ...       ...            ...\n",
              "153159  fffcd0960ee309b5  0.033246  ...  0.012084       0.000247\n",
              "153160  fffd7a9a6eb32c16  0.038302  ...  0.017371       0.033007\n",
              "153161  fffda9e8d6fafa9e  0.000974  ...  0.001298       0.000321\n",
              "153162  fffe8f1340a79fc2  0.008781  ...  0.007857       0.022365\n",
              "153163  ffffce3fb183ee80  0.996695  ...  0.286736       0.001376\n",
              "\n",
              "[153164 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4Wbxm52fVA5"
      },
      "source": [
        "submission_binary.to_csv('submission_binary_relevance_improved.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haK17eySkFSR"
      },
      "source": [
        "### Classifier Chains"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrw3-rZJkI2k"
      },
      "source": [
        "from scipy.sparse import csr_matrix, hstack\n",
        "\n",
        "def add_feature(X, feature_to_add):\n",
        "    '''\n",
        "    Returns sparse feature matrix with added feature.\n",
        "    feature_to_add can also be a list of features.\n",
        "    '''\n",
        "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr16kzBUlhmC"
      },
      "source": [
        "submission_chain_classifiers = pd.read_csv('/content/drive/My Drive/CS3244 Project/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zLeq36Qkgua",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a4bfa1ce-0383-4a59-80bd-66ea2570b796"
      },
      "source": [
        "columns = ['obscene','insult','toxic','severe_toxic','identity_hate','threat']\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "logreg = LogisticRegression(C=12.0)\n",
        "\n",
        "for label in columns:\n",
        "    print('... Processing {}'.format(label))\n",
        "    y = df_train[label]\n",
        "    # train the model using X_test_vectorized & y\n",
        "    logreg.fit(X_train_vectorized,y)\n",
        "    # compute the training accuracy\n",
        "    y_pred_X = logreg.predict(X_train_vectorized)\n",
        "    print('Training Accuracy is {}'.format(accuracy_score(y,y_pred_X)))\n",
        "    print('Training f1_score is {}'.format(f1_score(y,y_pred_X)))\n",
        "    print('Training Roc_auc_score is {}'.format(roc_auc_score(y,y_pred_X)))\n",
        "\n",
        "    # make predictions from df_test\n",
        "    test_y = logreg.predict(X_test_vectorized)\n",
        "    test_y_prob = logreg.predict_proba(X_test_vectorized)[:,1]\n",
        "    submission_chain_classifiers[label] = test_y_prob\n",
        "    # chain current label to X_train_vectorized\n",
        "    X_train_vectorized = add_feature(X_train_vectorized, y_pred_X)\n",
        "    print('Shape of X_train_vectorized is now {}'.format(X_train_vectorized.shape))\n",
        "    # chain current label predictions to X_test_vectorized\n",
        "    X_test_vectorized = add_feature(X_test_vectorized, test_y)\n",
        "    print('Shape of X_test_vectorized is now {}'.format(X_test_vectorized.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "... Processing obscene\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy is 0.9818200048881063\n",
            "Training f1_score is 0.8115866727284535\n",
            "Training Roc_auc_score is 0.8674318895780013\n",
            "Shape of X_train_vectorized is now (159571, 5001)\n",
            "Shape of X_test_vectorized is now (153164, 5001)\n",
            "... Processing insult\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy is 0.9761360146893859\n",
            "Training f1_score is 0.7296990346394094\n",
            "Training Roc_auc_score is 0.822736212024254\n",
            "Shape of X_train_vectorized is now (159571, 5002)\n",
            "Shape of X_test_vectorized is now (153164, 5002)\n",
            "... Processing toxic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy is 0.9634833397045829\n",
            "Training f1_score is 0.7879934509732582\n",
            "Training Roc_auc_score is 0.8493076362354165\n",
            "Shape of X_train_vectorized is now (159571, 5003)\n",
            "Shape of X_test_vectorized is now (153164, 5003)\n",
            "... Processing severe_toxic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy is 0.9927179750706582\n",
            "Training f1_score is 0.5351999999999999\n",
            "Training Roc_auc_score is 0.7089709194349271\n",
            "Shape of X_train_vectorized is now (159571, 5004)\n",
            "Shape of X_test_vectorized is now (153164, 5004)\n",
            "... Processing identity_hate\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy is 0.994466413070044\n",
            "Training f1_score is 0.6027890238416556\n",
            "Training Roc_auc_score is 0.7379663008228258\n",
            "Shape of X_train_vectorized is now (159571, 5005)\n",
            "Shape of X_test_vectorized is now (153164, 5005)\n",
            "... Processing threat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy is 0.998076091520389\n",
            "Training f1_score is 0.577716643741403\n",
            "Training Roc_auc_score is 0.7195427021488733\n",
            "Shape of X_train_vectorized is now (159571, 5006)\n",
            "Shape of X_test_vectorized is now (153164, 5006)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FItfRL7Tl_oO"
      },
      "source": [
        "submission_chain_classifiers.to_csv('submission_chain_classifiers.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2OFXE_1p8Zd"
      },
      "source": [
        "### skmultilearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9OJqdPIqne9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e334a31-fb9f-44b8-889d-3472435a3446"
      },
      "source": [
        "!pip install scikit-multilearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-multilearn in /usr/local/lib/python3.6/dist-packages (0.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPn4Ys6YmYXC"
      },
      "source": [
        "# using binary relevance\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "columns = ['obscene','insult','toxic','severe_toxic','identity_hate','threat']\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "logreg = LogisticRegression(C=12.0)\n",
        "\n",
        "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', norm='l2', max_features=5000) # ngram_range=(1,2)\n",
        "X_train_vectorized = vectorizer.fit_transform(df_train['lemmatize_text'])\n",
        "X_test_vectorized = vectorizer.transform(df_test['lemmatize_text'])\n",
        "\n",
        "# initialize binary relevance multi-label classifier\n",
        "# with a gaussian naive bayes base classifier\n",
        "classifier = BinaryRelevance(LogisticRegression(C=12.0, max_iter=300))\n",
        "\n",
        "y_train = df_train[columns]\n",
        "\n",
        "# train\n",
        "classifier.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# predict\n",
        "predictions = classifier.predict(X_train_vectorized)\n",
        "\n",
        "# accuracy\n",
        "print(\"Training Accuracy = \",accuracy_score(y_train,predictions))\n",
        "# print(\"Training F1_score = \",f1_score(y_train,predictions))\n",
        "# print(\"Training Roc_auc_score = \",roc_auc_score(y_train,predictions))\n",
        "# print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UFE7TjXu4tp"
      },
      "source": [
        "submission_df = pd.DataFrame.sparse.from_spmatrix(classifier.predict_proba(X_test_vectorized))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_KDNjXAvwGF"
      },
      "source": [
        "submission_binary_multilearn = pd.read_csv('/content/drive/My Drive/CS3244 Project/sample_submission.csv')\n",
        "submission_binary_multilearn[columns] = submission_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evtj_zvxwYlt"
      },
      "source": [
        "submission_binary_multilearn.to_csv('submission_binaryrelevance_multilearn.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_qAUUQlxTE-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "5ef6ad23-b0c5-4478-b073-bccc26ce0a13"
      },
      "source": [
        "submission_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.999304</td>\n",
              "      <td>0.971684</td>\n",
              "      <td>0.999637</td>\n",
              "      <td>0.195651</td>\n",
              "      <td>0.244325</td>\n",
              "      <td>0.162436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000360</td>\n",
              "      <td>0.002950</td>\n",
              "      <td>0.001487</td>\n",
              "      <td>0.000559</td>\n",
              "      <td>0.000757</td>\n",
              "      <td>0.000284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002007</td>\n",
              "      <td>0.001752</td>\n",
              "      <td>0.005824</td>\n",
              "      <td>0.000240</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>0.000008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.001825</td>\n",
              "      <td>0.002732</td>\n",
              "      <td>0.001768</td>\n",
              "      <td>0.001948</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.000129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.001381</td>\n",
              "      <td>0.003202</td>\n",
              "      <td>0.012235</td>\n",
              "      <td>0.000270</td>\n",
              "      <td>0.000390</td>\n",
              "      <td>0.000349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153159</th>\n",
              "      <td>0.002037</td>\n",
              "      <td>0.012269</td>\n",
              "      <td>0.033514</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.000255</td>\n",
              "      <td>0.000334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153160</th>\n",
              "      <td>0.006314</td>\n",
              "      <td>0.017226</td>\n",
              "      <td>0.034668</td>\n",
              "      <td>0.001989</td>\n",
              "      <td>0.032510</td>\n",
              "      <td>0.008440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153161</th>\n",
              "      <td>0.005997</td>\n",
              "      <td>0.001384</td>\n",
              "      <td>0.000868</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.000329</td>\n",
              "      <td>0.000214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153162</th>\n",
              "      <td>0.021722</td>\n",
              "      <td>0.008776</td>\n",
              "      <td>0.008539</td>\n",
              "      <td>0.000995</td>\n",
              "      <td>0.022550</td>\n",
              "      <td>0.007206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153163</th>\n",
              "      <td>0.895498</td>\n",
              "      <td>0.299050</td>\n",
              "      <td>0.996549</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.001395</td>\n",
              "      <td>0.001048</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153164 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0         1         2         3         4         5\n",
              "0       0.999304  0.971684  0.999637  0.195651  0.244325  0.162436\n",
              "1       0.000360  0.002950  0.001487  0.000559  0.000757  0.000284\n",
              "2       0.002007  0.001752  0.005824  0.000240  0.000087  0.000008\n",
              "3       0.001825  0.002732  0.001768  0.001948  0.000091  0.000129\n",
              "4       0.001381  0.003202  0.012235  0.000270  0.000390  0.000349\n",
              "...          ...       ...       ...       ...       ...       ...\n",
              "153159  0.002037  0.012269  0.033514  0.000116  0.000255  0.000334\n",
              "153160  0.006314  0.017226  0.034668  0.001989  0.032510  0.008440\n",
              "153161  0.005997  0.001384  0.000868  0.000124  0.000329  0.000214\n",
              "153162  0.021722  0.008776  0.008539  0.000995  0.022550  0.007206\n",
              "153163  0.895498  0.299050  0.996549  0.000177  0.001395  0.001048\n",
              "\n",
              "[153164 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0OCrwerxWrv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "2c243a17-885f-4a4a-c9eb-289e57cef30d"
      },
      "source": [
        "submission_binary_multilearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>0.999637</td>\n",
              "      <td>0.195651</td>\n",
              "      <td>0.999304</td>\n",
              "      <td>0.162436</td>\n",
              "      <td>0.971684</td>\n",
              "      <td>0.244325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>0.001487</td>\n",
              "      <td>0.000559</td>\n",
              "      <td>0.000360</td>\n",
              "      <td>0.000284</td>\n",
              "      <td>0.002950</td>\n",
              "      <td>0.000757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>0.005824</td>\n",
              "      <td>0.000240</td>\n",
              "      <td>0.002007</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.001752</td>\n",
              "      <td>0.000087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>0.001768</td>\n",
              "      <td>0.001948</td>\n",
              "      <td>0.001825</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.002732</td>\n",
              "      <td>0.000091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>0.012235</td>\n",
              "      <td>0.000270</td>\n",
              "      <td>0.001381</td>\n",
              "      <td>0.000349</td>\n",
              "      <td>0.003202</td>\n",
              "      <td>0.000390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153159</th>\n",
              "      <td>fffcd0960ee309b5</td>\n",
              "      <td>0.033514</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.002037</td>\n",
              "      <td>0.000334</td>\n",
              "      <td>0.012269</td>\n",
              "      <td>0.000255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153160</th>\n",
              "      <td>fffd7a9a6eb32c16</td>\n",
              "      <td>0.034668</td>\n",
              "      <td>0.001989</td>\n",
              "      <td>0.006314</td>\n",
              "      <td>0.008440</td>\n",
              "      <td>0.017226</td>\n",
              "      <td>0.032510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153161</th>\n",
              "      <td>fffda9e8d6fafa9e</td>\n",
              "      <td>0.000868</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.005997</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.001384</td>\n",
              "      <td>0.000329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153162</th>\n",
              "      <td>fffe8f1340a79fc2</td>\n",
              "      <td>0.008539</td>\n",
              "      <td>0.000995</td>\n",
              "      <td>0.021722</td>\n",
              "      <td>0.007206</td>\n",
              "      <td>0.008776</td>\n",
              "      <td>0.022550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153163</th>\n",
              "      <td>ffffce3fb183ee80</td>\n",
              "      <td>0.996549</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.895498</td>\n",
              "      <td>0.001048</td>\n",
              "      <td>0.299050</td>\n",
              "      <td>0.001395</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153164 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id     toxic  ...    insult  identity_hate\n",
              "0       00001cee341fdb12  0.999637  ...  0.971684       0.244325\n",
              "1       0000247867823ef7  0.001487  ...  0.002950       0.000757\n",
              "2       00013b17ad220c46  0.005824  ...  0.001752       0.000087\n",
              "3       00017563c3f7919a  0.001768  ...  0.002732       0.000091\n",
              "4       00017695ad8997eb  0.012235  ...  0.003202       0.000390\n",
              "...                  ...       ...  ...       ...            ...\n",
              "153159  fffcd0960ee309b5  0.033514  ...  0.012269       0.000255\n",
              "153160  fffd7a9a6eb32c16  0.034668  ...  0.017226       0.032510\n",
              "153161  fffda9e8d6fafa9e  0.000868  ...  0.001384       0.000329\n",
              "153162  fffe8f1340a79fc2  0.008539  ...  0.008776       0.022550\n",
              "153163  ffffce3fb183ee80  0.996549  ...  0.299050       0.001395\n",
              "\n",
              "[153164 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpupV5yAyRgg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "6b15f76d-1b15-424a-ed6e-e7f53e26742f"
      },
      "source": [
        "from skmultilearn.problem_transform import ClassifierChain\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "\n",
        "columns = ['obscene','insult','toxic','severe_toxic','identity_hate','threat']\n",
        "\n",
        "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', norm='l2', max_features=5000) # ngram_range=(1,2)\n",
        "X_train_vectorized = vectorizer.fit_transform(df_train['lemmatize_text'])\n",
        "X_test_vectorized = vectorizer.transform(df_test['lemmatize_text'])\n",
        "\n",
        "classifier = ClassifierChain(LogisticRegression(C=12.0))\n",
        "\n",
        "y_train = df_train[columns]\n",
        "\n",
        "# Training logistic regression model on train data\n",
        "classifier.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# predict\n",
        "predictions = classifier.predict(X_train_vectorized)\n",
        "\n",
        "# accuracy\n",
        "print(\"Accuracy = \",accuracy_score(y_train,predictions))\n",
        "print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.9309774332428825\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_GnOnvV5ZHY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEAh0laO5dFN"
      },
      "source": [
        "# Word2Vec Gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23D2fCCw5iF0"
      },
      "source": [
        "df_train = df_train.fillna(\"\")\n",
        "df_test = df_test.fillna(\"\")\n",
        "\n",
        "train_comments = df_train['lemmatize_text']\n",
        "test_comments = df_test['lemmatize_text']\n",
        "\n",
        "vocab_train = []\n",
        "vocab_test = []\n",
        "#print (len(train_comments))\n",
        "#print (len(test_comments))\n",
        "for sentences in train_comments:\n",
        "  vocab_train.append(sentences.split())\n",
        "for sentences in test_comments:\n",
        "  vocab_test.append(sentences.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCkQF5Dd6Uc6"
      },
      "source": [
        "vocab = vocab_train + vocab_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYzKf1bM6Y1U"
      },
      "source": [
        "from gensim.models import word2vec\n",
        "import gensim\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_T-6TuT6qsZ"
      },
      "source": [
        "num_features = 300    # Word vector dimensionality                      \n",
        "min_word_count = 40   # Minimum word count                        \n",
        "num_workers = 4       # Number of threads to run in parallel\n",
        "context = 10          # Context window size                                                                                    \n",
        "downsampling = 1e-3   # Downsample setting for frequent words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G62uzRVi7Lxp"
      },
      "source": [
        "#### The word2vec algorithms include skip-gram and CBOW models, using either hierarchical softmax or negative sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuJZ2en66zlW"
      },
      "source": [
        "w2v = word2vec.Word2Vec(vocab, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
        "w2v.init_sims(replace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-0D8Txa7N6G"
      },
      "source": [
        "def makeFeatureVec(words, model, num_features):\n",
        "    # Pre-initialize an empty numpy array (for speed)\n",
        "    featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
        "    #\n",
        "    nwords = 0\n",
        "    # \n",
        "    # Index2word is a list that contains the names of the words in \n",
        "    # the model's vocabulary. Convert it to a set, for speed \n",
        "    index2word_set = set(model.wv.index2word)\n",
        "    #\n",
        "    # Loop over each word in the review and, if it is in the model's\n",
        "    # vocaublary, add its feature vector to the total\n",
        "    for word in words:\n",
        "        if word in index2word_set: \n",
        "            nwords = nwords + 1\n",
        "            featureVec = np.add(featureVec, model[word])\n",
        "    # Divide the result by the number of words to get the average\n",
        "    if nwords == 0:\n",
        "        nwords = 1\n",
        "    featureVec = np.divide(featureVec, nwords)\n",
        "    return featureVec\n",
        "\n",
        "\n",
        "\n",
        "def getAvgFeatureVecs(reviews, model, num_features):\n",
        "    # Given a set of reviews (each one a list of words), calculate \n",
        "    # the average feature vector for each one and return a 2D numpy array \n",
        "    # Preallocate a 2D numpy array, for speed\n",
        "    reviewFeatureVecs = np.zeros((len(reviews), num_features), dtype=\"float32\")\n",
        "    counter = 0\n",
        "    # Loop through the reviews\n",
        "    for review in reviews:\n",
        "        # Call the function (defined above) that makes average feature vectors\n",
        "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
        "        counter = counter + 1\n",
        "    return reviewFeatureVecs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I71rugHk7far",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "05fc0276-6a1a-454f-f179-f56a0b7e90af"
      },
      "source": [
        "X = getAvgFeatureVecs(df_train[\"lemmatize_text\"], w2v, 300)\n",
        "x_test = getAvgFeatureVecs(df_test[\"lemmatize_text\"], w2v, 300)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmUNSGho7nX_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30715304-e102-4746-a7e3-e8bb542ee839"
      },
      "source": [
        "len(X[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-FBlMpkBbCc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "01c493b0-af1a-481c-b496-eec72b1dff6a"
      },
      "source": [
        "time()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
            "Wall time: 5.48 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMGgdNjl9rRT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "9d789d2a-3213-4fa7-cefc-c53310962c2c"
      },
      "source": [
        "from sklearn.metrics import log_loss,confusion_matrix,classification_report,roc_curve,auc, accuracy_score\n",
        "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict,train_test_split,GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import time\n",
        "\n",
        "target_col = ['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\n",
        "y = df_train[target_col]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "prd = np.zeros((x_test.shape[0],y.shape[1]))\n",
        "\n",
        "start = time.time()\n",
        "for i,col in enumerate(target_col):\n",
        "    lr = LogisticRegression(C=2,random_state = i,class_weight = 'balanced', max_iter=300)\n",
        "    print('Building {} model for column:{''}'.format(i,col))\n",
        "    lr.fit(X,y[col])\n",
        "    print(accuracy_score(y[col], lr.predict(X)))\n",
        "    prd[:,i] = lr.predict_proba(x_test)[:,1]\n",
        "end = time.time()\n",
        "\n",
        "print(\"total time: \", start - end)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building 0 model for column:toxic\n",
            "0.7533135720149651\n",
            "Building 1 model for column:severe_toxic\n",
            "0.8874294201327309\n",
            "Building 2 model for column:obscene\n",
            "0.8174104317200493\n",
            "Building 3 model for column:threat\n",
            "0.7921301489619041\n",
            "Building 4 model for column:insult\n",
            "0.800308326700967\n",
            "Building 5 model for column:identity_hate\n",
            "0.8184319205870741\n",
            "total time:  -56.259424924850464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st3FtpoL98NM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "dc0bd351-a258-4217-de25-16f4c5de722b"
      },
      "source": [
        "for col in target_col:\n",
        "    print(\"Column:\",col)\n",
        "    pred = lr.predict(X)\n",
        "    print('\\nConfusion matrix\\n',confusion_matrix(y[col],pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column: toxic\n",
            "\n",
            "Confusion matrix\n",
            " [[122190  22087]\n",
            " [  7827   7467]]\n",
            "Column: severe_toxic\n",
            "\n",
            "Confusion matrix\n",
            " [[129754  28222]\n",
            " [   263   1332]]\n",
            "Column: obscene\n",
            "\n",
            "Confusion matrix\n",
            " [[126742  24380]\n",
            " [  3275   5174]]\n",
            "Column: threat\n",
            "\n",
            "Confusion matrix\n",
            " [[129827  29266]\n",
            " [   190    288]]\n",
            "Column: insult\n",
            "\n",
            "Confusion matrix\n",
            " [[126770  24924]\n",
            " [  3247   4630]]\n",
            "Column: identity_hate\n",
            "\n",
            "Confusion matrix\n",
            " [[129605  28561]\n",
            " [   412    993]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK1Z_Sk_-bKI"
      },
      "source": [
        "prd_1 = pd.DataFrame(prd,columns=y.columns)\n",
        "# submit = pd.concat([test['id'],prd_1],axis=1)\n",
        "# submit.to_csv(r\"C:\\Users\\Admin\\Desktop\\Y2S1\\CS3244\\submission_w2v_7.csv\",index=False)\n",
        "# submit.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCliJF_R-yNz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "116afc93-d45d-4f21-c819-888790e264ef"
      },
      "source": [
        "sample_submission = pd.read_csv('/content/drive/My Drive/CS3244 Project/sample_submission.csv')\n",
        "sample_submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153159</th>\n",
              "      <td>fffcd0960ee309b5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153160</th>\n",
              "      <td>fffd7a9a6eb32c16</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153161</th>\n",
              "      <td>fffda9e8d6fafa9e</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153162</th>\n",
              "      <td>fffe8f1340a79fc2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153163</th>\n",
              "      <td>ffffce3fb183ee80</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153164 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  toxic  severe_toxic  ...  threat  insult  identity_hate\n",
              "0       00001cee341fdb12    0.5           0.5  ...     0.5     0.5            0.5\n",
              "1       0000247867823ef7    0.5           0.5  ...     0.5     0.5            0.5\n",
              "2       00013b17ad220c46    0.5           0.5  ...     0.5     0.5            0.5\n",
              "3       00017563c3f7919a    0.5           0.5  ...     0.5     0.5            0.5\n",
              "4       00017695ad8997eb    0.5           0.5  ...     0.5     0.5            0.5\n",
              "...                  ...    ...           ...  ...     ...     ...            ...\n",
              "153159  fffcd0960ee309b5    0.5           0.5  ...     0.5     0.5            0.5\n",
              "153160  fffd7a9a6eb32c16    0.5           0.5  ...     0.5     0.5            0.5\n",
              "153161  fffda9e8d6fafa9e    0.5           0.5  ...     0.5     0.5            0.5\n",
              "153162  fffe8f1340a79fc2    0.5           0.5  ...     0.5     0.5            0.5\n",
              "153163  ffffce3fb183ee80    0.5           0.5  ...     0.5     0.5            0.5\n",
              "\n",
              "[153164 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JMVHNxV-iEa"
      },
      "source": [
        "sample_submission[target_col] = prd_1\n",
        "sample_submission.to_csv('gensim_word2vec.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}